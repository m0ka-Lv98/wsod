{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from dataset import MedicalBboxDataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose\n",
    "import transform as transf\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision.ops.boxes import box_iou\n",
    "from torchvision.ops import nms\n",
    "import torchvision\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pdb\n",
    "import sys\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, models\n",
    "from make_dloader import make_data\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open('./config.yaml'))\n",
    "dataset_means = json.load(open(config['dataset']['mean_file']))\n",
    "#_, _, _, dataset_val, _ = make_data()\n",
    "dataset_val = torch.load(f'/data/unagi0/masaoka/val_all1.pt')\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=1, shuffle=False, \n",
    "                                num_workers=4, collate_fn=bbox_collate)\n",
    "unnormalize = transf.UnNormalize(dataset_means['mean'], dataset_means['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.ops import roi_align, nms\n",
    "from utils import calc_iou\n",
    "import torchvision.models as models\n",
    "import yaml\n",
    "from torchvision.ops.boxes import box_iou\n",
    "import torch.nn.functional as F\n",
    "\n",
    "config = yaml.safe_load(open('./config.yaml'))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, eps=1e-7,reduction='none'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logit = F.softmax(input, dim=1)\n",
    "        logit = logit.clamp(self.eps, 1. - self.eps)\n",
    "        logit_ls = torch.log(logit)\n",
    "        loss = F.nll_loss(logit_ls, target, reduction=\"none\")\n",
    "        view = target.size() + (1,)\n",
    "        index = target.view(*view)\n",
    "        loss = loss * (1 - logit.gather(1, index).squeeze(1)) ** self.gamma # focal loss\n",
    "        if self.reduction=='none':\n",
    "            return loss\n",
    "\n",
    "        return loss.sum()\n",
    "\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def  __init__(self,size_list=[]):\n",
    "        super().__init__()\n",
    "        assert len(size_list)>0\n",
    "        self.avgpool_list = []\n",
    "        for size in size_list:\n",
    "            self.avgpool_list.append(nn.Sequential(nn.AdaptiveAvgPool2d(size),\n",
    "                                                    nn.Flatten()))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        vec = []\n",
    "        for avgpool in self.avgpool_list:\n",
    "            vec.append(avgpool(x))\n",
    "        vec = torch.cat(vec,1)\n",
    "        return vec\n",
    "\n",
    "class _ROIPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, inputs, rois):\n",
    "        #rois: bs,2000,4 \n",
    "        #output: bs, 2000, ch, h, w\n",
    "        rois = [r for r in rois]\n",
    "        h, w = inputs.shape[2], inputs.shape[3]\n",
    "        res = roi_align(inputs, rois, 7, spatial_scale=w/512)\n",
    "        return res\n",
    "\n",
    "class vector_extractor(nn.Module):\n",
    "    \"\"\"input: images, proposals\n",
    "         output: feature vector\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        layers = list(model.children())[:-2]\n",
    "        self.feature_map = nn.Sequential(*layers)\n",
    "        self.roi_pool = _ROIPool()\n",
    "        #self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feature_vector = nn.Sequential(ASPP([1,2]),\n",
    "                                            #nn.AdaptiveAvgPool2d(1),\n",
    "                                            nn.Flatten(),\n",
    "                                            nn.Linear(512*(5), 500),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.BatchNorm1d(500),\n",
    "                                            nn.Linear(500, 500),\n",
    "                                            nn.BatchNorm1d(500),\n",
    "                                            nn.ReLU(inplace=True))\n",
    "    def forward(self, inputs, rois):\n",
    "        f = self.feature_map(inputs)\n",
    "        f = self.roi_pool(f, rois)\n",
    "        #f = self.gap(f).view(f.shape[0], f.shape[1]) #batch*proposal, ch\n",
    "        f = self.feature_vector(f) \n",
    "        return f\n",
    "    \n",
    "class MIDN(nn.Module):\n",
    "    \"\"\"input: feature vector, labels\n",
    "         output: scores per proposal, loss\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_in = 500\n",
    "        self.layer_c = nn.Linear(c_in, 4)\n",
    "        self.layer_d = nn.Linear(c_in, 4)\n",
    "        self.softmax_c = nn.Softmax(dim=2)\n",
    "        self.softmax_d = nn.Softmax(dim=1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    def forward(self, inputs, labels, num):\n",
    "        bs, proposal = inputs.shape[0]//num, num\n",
    "        x_c = self.layer_c(inputs).view(bs, proposal, -1) #bs, proposal, 4\n",
    "        x_d = self.layer_d(inputs).view(bs, proposal, -1)\n",
    "        sigma_c = self.softmax_c(x_c)\n",
    "        sigma_d = self.softmax_d(x_d)\n",
    "        x_r = sigma_c * sigma_d #bs, proposal, 4\n",
    "        phi_c = x_r.sum(dim=1) #bs, 4\n",
    "        print((torch.max(x_r,1))[0].shape,phi_c.shape,x_r.shape)\n",
    "        scaled = x_r/torch.max(x_r,1)[0]*phi_c\n",
    "        if not self.training:\n",
    "            print(scaled)\n",
    "            return scaled\n",
    "        loss = self.loss(phi_c, torch.max(labels,1)[1])\n",
    "        return   scaled, loss#phi_c.unsqueeze(1), loss # sigma_c,loss#x_r,loss\n",
    "        \n",
    "\n",
    "class ICR(nn.Module):\n",
    "    \"\"\"input: feature vector (bs*proposal, ch)\n",
    "                     k-1th proposal scores(bs, proposal,3or4)\n",
    "                     supervision (label) (bs)\n",
    "                     ROI proposals\n",
    "         output: refined proposal scores, loss\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_in = 500\n",
    "        self.I_t = 0.5\n",
    "        self.fc = nn.Linear(c_in, 4)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        #self.loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        self.loss = FocalLoss(gamma=2)\n",
    "        \"\"\"self.y_k = torch.zeros(bs, proposal, 4).cuda()\n",
    "        self.y_k[:, :, 3] = 1\n",
    "        self.w = torch.zeros(bs, proposal).cuda()\"\"\"\n",
    "        \n",
    "    def forward(self, inputs, pre_score, labels, rois, num):\n",
    "        bs, proposal = inputs.shape[0]//num, num\n",
    "        xr_k = self.fc(inputs).view(bs, proposal, -1) #bs, proposal, 4\n",
    "        xr_k = self.softmax(xr_k)\n",
    "        \n",
    "        _xr_k = xr_k.view(bs*proposal, -1)\n",
    "        self.y_k = torch.zeros(bs, proposal, 4).cuda()\n",
    "        self.y_k[:, :, 3] = 1\n",
    "        self.w = torch.zeros(bs, proposal).cuda()\n",
    "        I = torch.zeros(bs, proposal)\n",
    "        for batch in range(bs):\n",
    "            for c in range(3):\n",
    "                if labels[batch][c]:\n",
    "                    #print(f'label{c}')\n",
    "                    #m = torch.max(pre_score[batch, :, c], 0)\n",
    "                    #x = m[0].item()\n",
    "                    #j = m[1].item()\n",
    "                    j_list = (pre_score[batch,:,c]>0.5).nonzero().squeeze()\n",
    "                    x_list = pre_score[batch,j_list,c]\n",
    "                    if (j_list).size() == torch.Size([0]) or (j_list).size() == torch.Size([1]) or (j_list).size() == torch.Size([]):\n",
    "                        m = torch.max(pre_score[batch, :, c], 0)\n",
    "                        x = m[0].item()\n",
    "                        j = m[1].item()\n",
    "                        x_list = [x]\n",
    "                        j_list =[j]\n",
    "                    mat = box_iou(rois[batch], rois[batch][j_list])\n",
    "                    for i,j in enumerate(j_list):\n",
    "                        for r in range(proposal):\n",
    "                            _I = mat[r][i]\n",
    "                            if _I > I[batch, r]:\n",
    "                                I[batch, r] = _I\n",
    "                                self.w[batch, r] = x_list[i]\n",
    "                                if _I > self.I_t:\n",
    "                                    #print(f'next supervision index{r}')\n",
    "                                    self.y_k[batch, r, c] = 1\n",
    "                                    self.y_k[batch, r, 3] = 0\n",
    "        self.y_k = self.y_k.view(bs*proposal, -1)\n",
    "        self.w = self.w.view(bs*proposal, 1)\n",
    "        loss = self.loss(_xr_k.cuda().float(), torch.max(self.y_k, 1)[1])\n",
    "        loss = torch.mean(self.w*loss)\n",
    "        if not self.training:\n",
    "            return xr_k\n",
    "        return xr_k, loss\n",
    "\n",
    "class OICR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.v_extractor = vector_extractor()\n",
    "        self.midn = MIDN()\n",
    "        self.icr1 = ICR()\n",
    "        self.icr2 = ICR()\n",
    "        self.icr3 = ICR()\n",
    "        \n",
    "    def forward(self, inputs, labels, rois, num):\n",
    "        if self.training:\n",
    "            labels = labels.squeeze()\n",
    "            rois = rois.squeeze()\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            x, midn_loss = self.midn(v, labels, num)\n",
    "            x, loss1 = self.icr1(v, x, labels, rois, num)\n",
    "            x, loss2 = self.icr2(v, x, labels, rois, num)\n",
    "            x, loss3 = self.icr3(v, x, labels, rois, num) \n",
    "            print(midn_loss,loss1,loss2,loss3)\n",
    "            loss = midn_loss + loss1 + loss2 + loss3\n",
    "            return x, loss.unsqueeze(0)  \n",
    "        else:\n",
    "            self.three = torch.tensor([3.]).cuda()\n",
    "            self.inf = torch.tensor([-1.]).cuda()\n",
    "            #rois = rois.squeeze()\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            x = self.midn(v, labels, num)\n",
    "            x = self.icr1(v, x, labels, rois, num) \n",
    "            x, rois = x[0], rois[0].cuda()\n",
    "            h = 0\n",
    "            while(1):\n",
    "                if torch.max(x[h],0)[1]==3:\n",
    "                    x = torch.cat([x[:h],x[h+1:]])\n",
    "                    rois = torch.cat([rois[:h],rois[h+1:]])\n",
    "                else:\n",
    "                    h+1\n",
    "                if len(x)==h:\n",
    "                    break\n",
    "            print(x.size())\n",
    "            if x.size() == torch.Size([0,4]):\n",
    "                return [],[],[]\n",
    "            s, i = torch.max(x, 1)\n",
    "            s = torch.where(i==self.three,self.inf,s)\n",
    "            sort = torch.argsort(s, descending=True)\n",
    "            s, i = s.view(-1,1), i.view(-1,1).cuda().float()\n",
    "            #print(s.shape, i.shape, rois.shape)\n",
    "            cat = torch.cat([s, i ,rois], dim=1)\n",
    "            cat = cat[sort, :]\n",
    "            scores = cat[:, 0]\n",
    "            labels = cat[:, 1]\n",
    "            bboxes = cat[:, 2:]\n",
    "            return scores, labels, bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OICR(\n",
       "  (v_extractor): vector_extractor(\n",
       "    (feature_map): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (roi_pool): _ROIPool()\n",
       "    (feature_vector): Sequential(\n",
       "      (0): ASPP()\n",
       "      (1): Flatten()\n",
       "      (2): Linear(in_features=2560, out_features=500, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (midn): MIDN(\n",
       "    (layer_c): Linear(in_features=500, out_features=4, bias=True)\n",
       "    (layer_d): Linear(in_features=500, out_features=4, bias=True)\n",
       "    (softmax_c): Softmax(dim=2)\n",
       "    (softmax_d): Softmax(dim=1)\n",
       "    (loss): CrossEntropyLoss()\n",
       "  )\n",
       "  (icr1): ICR(\n",
       "    (fc): Linear(in_features=500, out_features=4, bias=True)\n",
       "    (softmax): Softmax(dim=2)\n",
       "    (loss): FocalLoss()\n",
       "  )\n",
       "  (icr2): ICR(\n",
       "    (fc): Linear(in_features=500, out_features=4, bias=True)\n",
       "    (softmax): Softmax(dim=2)\n",
       "    (loss): FocalLoss()\n",
       "  )\n",
       "  (icr3): ICR(\n",
       "    (fc): Linear(in_features=500, out_features=4, bias=True)\n",
       "    (softmax): Softmax(dim=2)\n",
       "    (loss): FocalLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oicr = OICR()\n",
    "oicr.load_state_dict(torch.load(\"/data/unagi0/masaoka/wsod/model/oicr/ResNet18aspplight0.0002_1.pt\"))\n",
    "oicr.cuda()\n",
    "oicr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_caption(image, box, caption):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) torch.Size([1, 4]) torch.Size([1, 2000, 4])\n",
      "tensor([[[0.0468, 0.0096, 0.0359, 0.0464],\n",
      "         [0.0409, 0.0175, 0.0341, 0.1122],\n",
      "         [0.0381, 0.0163, 0.0327, 0.1264],\n",
      "         ...,\n",
      "         [0.0541, 0.0141, 0.0416, 0.0480],\n",
      "         [0.0224, 0.0063, 0.0225, 0.1533],\n",
      "         [0.1102, 0.0115, 0.0413, 0.0369]]], device='cuda:0')\n",
      "torch.Size([0, 4])\n",
      "torch.Size([1, 4]) torch.Size([1, 4]) torch.Size([1, 2000, 4])\n",
      "tensor([[[2.1748e-01, 3.9069e-03, 1.8839e-03, 5.6039e-05],\n",
      "         [1.1188e-03, 6.1148e-04, 1.5149e-04, 1.2430e-03],\n",
      "         [2.2029e-02, 3.7546e-02, 1.2798e-03, 2.9888e-04],\n",
      "         ...,\n",
      "         [2.3085e-01, 2.7855e-03, 2.0236e-03, 5.3442e-05],\n",
      "         [3.4687e-01, 9.9974e-05, 8.0871e-05, 1.1474e-05],\n",
      "         [3.6545e-01, 4.6365e-05, 4.6072e-05, 7.8483e-06]]], device='cuda:0')\n",
      "torch.Size([0, 4])\n",
      "torch.Size([1, 4]) torch.Size([1, 4]) torch.Size([1, 2000, 4])\n",
      "tensor([[[0.0427, 0.0039, 0.0131, 0.0037],\n",
      "         [0.0528, 0.0046, 0.0152, 0.0035],\n",
      "         [0.3434, 0.0019, 0.0040, 0.0016],\n",
      "         ...,\n",
      "         [0.0173, 0.0037, 0.0070, 0.0216],\n",
      "         [0.0416, 0.0038, 0.0128, 0.0037],\n",
      "         [0.0326, 0.0419, 0.0051, 0.0091]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-6adb177bd4e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdata2target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mrois\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p_bboxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_anchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moicr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-186-1121b7341c41>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels, rois, num)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0micr1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-186-1121b7341c41>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, pre_score, labels, rois, num)\u001b[0m\n\u001b[1;32m    160\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                             \u001b[0m_I\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                             \u001b[0;32mif\u001b[0m \u001b[0m_I\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                                 \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_I\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for idx, data in enumerate(dataloader_val):\n",
    "    with torch.no_grad():\n",
    "        st = time.time()\n",
    "        labels, n, t, v, u= data2target(data)\n",
    "        rois = data[\"p_bboxes\"][0][:2000].unsqueeze(0).cuda().float()\n",
    "        scores, classification, transformed_anchors = oicr(data['img'].cuda().float(), labels,rois,2000)\n",
    "        if len(scores)==0:\n",
    "            continue\n",
    "        print('Elapsed time: {}'.format(time.time()-st))\n",
    "        idxs = np.where(scores.cpu()>0.01)\n",
    "        print(idxs)\n",
    "        data['img'] = data['img'].squeeze(dim=0)\n",
    "        \n",
    "        print(scores)\n",
    "        print(classification)\n",
    "        img = unnormalize(data)['img'].copy() \n",
    "        img[img<0] = 0\n",
    "        img[img>255] = 255\n",
    "        for j in range(idxs[0].shape[0]):\n",
    "            if int(classification[idxs[0][j]]) == 3:\n",
    "                continue\n",
    "            bbox = transformed_anchors[idxs[0][j], :]\n",
    "            x1 = int(bbox[0])\n",
    "            y1 = int(bbox[1])\n",
    "            x2 = int(bbox[2])\n",
    "            y2 = int(bbox[3])\n",
    "            label_name_ = dataset_val.labels[int(classification[idxs[0][j]])]\n",
    "            draw_caption(img, (x1, y1, x2, y2), label_name_)\n",
    "            if label_name_ == \"ulcer\":\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 255, 255), thickness=2) #黄色\n",
    "            elif label_name_ == \"torose lesion\":\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 255, 255), thickness=2) #青\n",
    "            else:\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 255, 255), thickness=2) #赤\n",
    "                \n",
    "        iou = box_iou(rois[0], rois[0][1].unsqueeze(0))\n",
    "        print(iou.shape)\n",
    "        for i in range(len(data[\"bboxes\"])):\n",
    "            x1 = int(data[\"bboxes\"][i][0][0])\n",
    "            y1 = int(data[\"bboxes\"][i][0][1])\n",
    "            x2 = int(data[\"bboxes\"][i][0][2])\n",
    "            y2 = int(data[\"bboxes\"][i][0][3])\n",
    "            print(x1,y1,x2,y2)\n",
    "            label_name = dataset_val.labels[int(data[\"labels\"][i])]\n",
    "            draw_caption(img, (x1, y1, x2, y2), label_name)\n",
    "            if label_name == \"ulcer\":\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 255, 0), thickness=6) #黄色\n",
    "            elif label_name == \"torose lesion\":\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 0, 255), thickness=6) #青\n",
    "            else:\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=6)  #赤\n",
    "            print(label_name)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        x+=1\n",
    "        if x == 50:\n",
    "            break\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((x>3)).nonzero().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4],\n",
       "        [5]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[(x*(x>3)).nonzero()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7372])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.tensor([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.randn(scores.shape).cuda()\n",
    "t = transformed_anchors\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms(t,s,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
