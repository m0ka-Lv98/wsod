{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "import json\n",
    "import torch\n",
    "import transform as transf\n",
    "from torchvision.transforms import Compose\n",
    "import yaml\n",
    "from dataset import MedicalBboxDataset\n",
    "from model import ResNet50\n",
    "import numpy as np\n",
    "from utils import bbox_collate, data2target, calc_confusion_matrix, draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_coco_weak(model, val, threshold=0.05):\n",
    "    config = yaml.safe_load(open('./config.yaml'))\n",
    "    dataset_means = json.load(open(config['dataset']['mean_file']))\n",
    "    dataset_all = MedicalBboxDataset(\n",
    "        config['dataset']['annotation_file'],\n",
    "        config['dataset']['image_root'])\n",
    "    if 'class_integration' in config['dataset']:\n",
    "        dataset_all = dataset_all.integrate_classes(\n",
    "            config['dataset']['class_integration']['new'],\n",
    "            config['dataset']['class_integration']['map'])\n",
    "    \n",
    "    transform = Compose([\n",
    "        transf.ToFixedSize([config['inputsize']] * 2),  # inputsize x inputsizeの画像に変換\n",
    "        transf.Normalize(dataset_means['mean'], dataset_means['std']),\n",
    "        transf.HWCToCHW()\n",
    "        ])\n",
    "\n",
    "    dataset = dataset_all.split(val, config['dataset']['split_file'])\n",
    "    dataset.set_transform(transform)\n",
    "    \n",
    "    model = ResNet50()\n",
    "    model.load_state_dict(torch.load(f\"/data/unagi0/masaoka/wsod/model/resnet50_classify{val}_ulcer.pt\"))\n",
    "    \n",
    "\n",
    "    results = []\n",
    "    image_ids = []\n",
    "    for index in range(len(dataset)):\n",
    "        data = dataset[index]\n",
    "        data['img'] = torch.from_numpy(data['img']) #.permute(2, 0, 1)\n",
    "        # run network\n",
    "        #scores, labels, boxes = model(data['img'].cuda().float().unsqueeze(dim=0))\n",
    "        scores, labels, boxes = model(data['img'].unsqueeze(0).float(), e=True, aug=False)\n",
    "        scores = scores.cpu()\n",
    "        labels = labels.cpu()\n",
    "        boxes  = boxes.cpu()\n",
    "\n",
    "        \n",
    "\n",
    "        if boxes.shape[0] > 0:\n",
    "            # change to (x, y, w, h) (MS COCO standard)\n",
    "            boxes[:, 2] -= boxes[:, 0]\n",
    "            boxes[:, 3] -= boxes[:, 1]\n",
    "\n",
    "            # compute predicted labels and scores\n",
    "            #for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            for box_id in range(boxes.shape[0]):\n",
    "                score = float(scores[box_id])\n",
    "                label = int(labels[box_id])\n",
    "                box = boxes[box_id, :]\n",
    "                \n",
    "\n",
    "                # scores are sorted, so we can break\n",
    "                if score < threshold:\n",
    "                    break\n",
    "\n",
    "                # append detection for each positively labeled class\n",
    "                image_result = {\n",
    "                        'image_id'    : dataset.imgids[index],\n",
    "                        'category_id' : dataset.label_to_coco_label(label),\n",
    "                        'score'       : float(score),\n",
    "                        'bbox'        : box.tolist(),\n",
    "                    }\n",
    "\n",
    "                # append detection to results\n",
    "                results.append(image_result)\n",
    "\n",
    "        # append image to list of processed images\n",
    "        image_ids.append(dataset.imgids[index])\n",
    "\n",
    "        # print progress\n",
    "        print('{}/{}'.format(index+1, len(dataset)), end='\\r')\n",
    "\n",
    "    if not len(results):\n",
    "            print(\"error\")\n",
    "            return\n",
    "        # write output\n",
    "    json.dump(results, open(f\"/data/unagi0/masaoka/wsod/result_bbox/resnet50_v{val}_ulcer.json\", 'w'), indent=4)\n",
    "\n",
    "    # load results in COCO evaluation tool\n",
    "    coco_true = dataset.coco\n",
    "    coco_pred = coco_true.loadRes(f\"/data/unagi0/masaoka/wsod/result_bbox/resnet50_v{val}_ulcer.json\")\n",
    "\n",
    "    # run COCO evaluation\n",
    "    coco_eval = COCOeval(coco_true, coco_pred, 'bbox')\n",
    "    coco_eval.params.imgIds = image_ids\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.53s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.87s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n"
     ]
    }
   ],
   "source": [
    "evaluate_coco_weak(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classify(val, threshold=0.05):\n",
    "    config = yaml.safe_load(open('./config.yaml'))\n",
    "    dataset_means = json.load(open(config['dataset']['mean_file']))\n",
    "    dataset_all = MedicalBboxDataset(\n",
    "        config['dataset']['annotation_file'],\n",
    "        config['dataset']['image_root'])\n",
    "    if 'class_integration' in config['dataset']:\n",
    "        dataset_all = dataset_all.integrate_classes(\n",
    "            config['dataset']['class_integration']['new'],\n",
    "            config['dataset']['class_integration']['map'])\n",
    "    \n",
    "    transform = Compose([\n",
    "        transf.ToFixedSize([config['inputsize']] * 2),  # inputsize x inputsizeの画像に変換\n",
    "        transf.Normalize(dataset_means['mean'], dataset_means['std']),\n",
    "        transf.HWCToCHW()\n",
    "        ])\n",
    "\n",
    "    dataset = dataset_all.split(val, config['dataset']['split_file'])\n",
    "    dataset.set_transform(transform)\n",
    "    dataloader_val = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=False, \n",
    "                                                num_workers=4, collate_fn=bbox_collate)\n",
    "    model = ResNet50()\n",
    "    model.load_state_dict(torch.load(f\"/data/unagi0/masaoka/wsod/model/resnet50_classify1.pt\"))\n",
    "    ite = 0\n",
    "    gt = [0,0,0,0]\n",
    "    tpa = np.zeros(3)\n",
    "    fpa = np.zeros(3)\n",
    "    tna = 0\n",
    "    fna = np.zeros(3)\n",
    "    with torch.no_grad():\n",
    "        for i, d in enumerate(dataloader_val):\n",
    "            scores = torch.sigmoid(model(d['img'].cuda().float()))\n",
    "            output = scores.cpu().data.numpy()\n",
    "            output = np.where(output>0.5,1,0)\n",
    "            target, n, t, v, u = data2target(d, torch.from_numpy(output))\n",
    "            target = target.cpu().data.numpy()\n",
    "            gt = np.array([n,t,v,u])\n",
    "            tp, fp, fn, tn = calc_confusion_matrix(output, target, gt)\n",
    "            tpa += tp\n",
    "            fpa += fp\n",
    "            fna += fn\n",
    "            tna += tn\n",
    "                \n",
    "            print(f'{i}/{len(dataloader_val)}', end = '\\r')\n",
    "    print(gt,tpa,fpa,tna,fna)\n",
    "    return gt,tpa,fpa,tna,fna"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
