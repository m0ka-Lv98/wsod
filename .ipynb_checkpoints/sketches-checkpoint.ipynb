{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SA(nn.Module):\n",
    "    def __init__(self, i_ch):\n",
    "        super().__init__()\n",
    "        self.i_ch = i_ch\n",
    "        self.o_ch = 1000\n",
    "        self.q = nn.Conv2d(i_ch, self.o_ch, 1)\n",
    "        self.k = nn.Conv2d(i_ch, self.o_ch, 1)\n",
    "        self.v = nn.Conv2d(i_ch, i_ch, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        b_size, h = input.shape[0], input.shape[2]\n",
    "\n",
    "        #input is feature map\n",
    "        query = self.q(input.clone())\n",
    "        key = self.k(input.clone())\n",
    "        value = self.v(input.clone())\n",
    "\n",
    "        query = query.view(b_size, self.o_ch, -1).permute(0,2,1)\n",
    "        key = key.view(b_size, self.o_ch, -1)\n",
    "        s = torch.bmm(query, key)\n",
    "\n",
    "        alpha = torch.sigmoid(s)\n",
    "        value = value.view(b_size, self.i_ch, -1)\n",
    "        o = torch.bmm(value, alpha)\n",
    "        o = o.view(b_size, self.i_ch, h, -1)\n",
    "        return o\n",
    "\n",
    "class CA(nn.Module):\n",
    "    def __init__(self, i_ch):\n",
    "        super().__init__()\n",
    "        self.i_ch = i_ch\n",
    "    def forward(self, input):\n",
    "        b_size, h = input.shape[0], input.shape[2]\n",
    "        query = input.clone().view(b_size, self.i_ch, -1) #b,c,h*w\n",
    "        key = input.clone().view(b_size, self.i_ch, -1)\n",
    "        value = input.clone().view(b_size, self.i_ch, -1)\n",
    "        gamma = torch.sigmoid(torch.bmm(query, key.permute(0,2,1))) #b,c,c\n",
    "        r = torch.bmm(value.permute(0,2,1), gamma) #b,h*w,c\n",
    "        r = r.permute(0,2,1) #b,c,h*w\n",
    "        r = r.view(b_size, self.i_ch, h, -1)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=3, tap=False):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes #torose, vascular, ulcer\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        layers = list(model.children())[:-2] #特徴マップまで\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.sa = SA(2048)\n",
    "        self.ca = CA(2048)\n",
    "        self.s = torch.tensor([0.], requires_grad=True)\n",
    "        self.c = torch.tensor([0.], requires_grad=True)\n",
    "        self._parameters[\"s\"] = self.s\n",
    "        self._parameters[\"c\"] = self.c\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(4096, self.num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extractor(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(-1, 4096)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def fc_w(self):\n",
    "        return self.fc.weight\n",
    "    def extractor(self, x):\n",
    "        feature = self.layers(x)\n",
    "        o = self.sa(feature)\n",
    "        r = self.ca(feature)\n",
    "        s_feature = feature + self.s*o\n",
    "        c_feature = feature + self.c*o\n",
    "        cat_feature = torch.cat([s_feature, c_feature], dim=1)\n",
    "        return cat_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((5,3,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2098, -0.4528,  0.0946],\n",
       "        [-0.0941, -0.5150, -0.0354],\n",
       "        [-0.1479, -0.4829,  0.0367],\n",
       "        [-0.1245, -0.4903, -0.0226],\n",
       "        [-0.1671, -0.6127, -0.0078]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_name',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'c',\n",
       " 'c',\n",
       " 'ca',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'extractor',\n",
       " 'fc',\n",
       " 'fc_w',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'gap',\n",
       " 'half',\n",
       " 'layers',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_classes',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 's',\n",
       " 's',\n",
       " 'sa',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "c\n",
      "layers.0.weight\n",
      "layers.1.weight\n",
      "layers.1.bias\n",
      "layers.4.0.conv1.weight\n",
      "layers.4.0.bn1.weight\n",
      "layers.4.0.bn1.bias\n",
      "layers.4.0.conv2.weight\n",
      "layers.4.0.bn2.weight\n",
      "layers.4.0.bn2.bias\n",
      "layers.4.0.conv3.weight\n",
      "layers.4.0.bn3.weight\n",
      "layers.4.0.bn3.bias\n",
      "layers.4.0.downsample.0.weight\n",
      "layers.4.0.downsample.1.weight\n",
      "layers.4.0.downsample.1.bias\n",
      "layers.4.1.conv1.weight\n",
      "layers.4.1.bn1.weight\n",
      "layers.4.1.bn1.bias\n",
      "layers.4.1.conv2.weight\n",
      "layers.4.1.bn2.weight\n",
      "layers.4.1.bn2.bias\n",
      "layers.4.1.conv3.weight\n",
      "layers.4.1.bn3.weight\n",
      "layers.4.1.bn3.bias\n",
      "layers.4.2.conv1.weight\n",
      "layers.4.2.bn1.weight\n",
      "layers.4.2.bn1.bias\n",
      "layers.4.2.conv2.weight\n",
      "layers.4.2.bn2.weight\n",
      "layers.4.2.bn2.bias\n",
      "layers.4.2.conv3.weight\n",
      "layers.4.2.bn3.weight\n",
      "layers.4.2.bn3.bias\n",
      "layers.5.0.conv1.weight\n",
      "layers.5.0.bn1.weight\n",
      "layers.5.0.bn1.bias\n",
      "layers.5.0.conv2.weight\n",
      "layers.5.0.bn2.weight\n",
      "layers.5.0.bn2.bias\n",
      "layers.5.0.conv3.weight\n",
      "layers.5.0.bn3.weight\n",
      "layers.5.0.bn3.bias\n",
      "layers.5.0.downsample.0.weight\n",
      "layers.5.0.downsample.1.weight\n",
      "layers.5.0.downsample.1.bias\n",
      "layers.5.1.conv1.weight\n",
      "layers.5.1.bn1.weight\n",
      "layers.5.1.bn1.bias\n",
      "layers.5.1.conv2.weight\n",
      "layers.5.1.bn2.weight\n",
      "layers.5.1.bn2.bias\n",
      "layers.5.1.conv3.weight\n",
      "layers.5.1.bn3.weight\n",
      "layers.5.1.bn3.bias\n",
      "layers.5.2.conv1.weight\n",
      "layers.5.2.bn1.weight\n",
      "layers.5.2.bn1.bias\n",
      "layers.5.2.conv2.weight\n",
      "layers.5.2.bn2.weight\n",
      "layers.5.2.bn2.bias\n",
      "layers.5.2.conv3.weight\n",
      "layers.5.2.bn3.weight\n",
      "layers.5.2.bn3.bias\n",
      "layers.5.3.conv1.weight\n",
      "layers.5.3.bn1.weight\n",
      "layers.5.3.bn1.bias\n",
      "layers.5.3.conv2.weight\n",
      "layers.5.3.bn2.weight\n",
      "layers.5.3.bn2.bias\n",
      "layers.5.3.conv3.weight\n",
      "layers.5.3.bn3.weight\n",
      "layers.5.3.bn3.bias\n",
      "layers.6.0.conv1.weight\n",
      "layers.6.0.bn1.weight\n",
      "layers.6.0.bn1.bias\n",
      "layers.6.0.conv2.weight\n",
      "layers.6.0.bn2.weight\n",
      "layers.6.0.bn2.bias\n",
      "layers.6.0.conv3.weight\n",
      "layers.6.0.bn3.weight\n",
      "layers.6.0.bn3.bias\n",
      "layers.6.0.downsample.0.weight\n",
      "layers.6.0.downsample.1.weight\n",
      "layers.6.0.downsample.1.bias\n",
      "layers.6.1.conv1.weight\n",
      "layers.6.1.bn1.weight\n",
      "layers.6.1.bn1.bias\n",
      "layers.6.1.conv2.weight\n",
      "layers.6.1.bn2.weight\n",
      "layers.6.1.bn2.bias\n",
      "layers.6.1.conv3.weight\n",
      "layers.6.1.bn3.weight\n",
      "layers.6.1.bn3.bias\n",
      "layers.6.2.conv1.weight\n",
      "layers.6.2.bn1.weight\n",
      "layers.6.2.bn1.bias\n",
      "layers.6.2.conv2.weight\n",
      "layers.6.2.bn2.weight\n",
      "layers.6.2.bn2.bias\n",
      "layers.6.2.conv3.weight\n",
      "layers.6.2.bn3.weight\n",
      "layers.6.2.bn3.bias\n",
      "layers.6.3.conv1.weight\n",
      "layers.6.3.bn1.weight\n",
      "layers.6.3.bn1.bias\n",
      "layers.6.3.conv2.weight\n",
      "layers.6.3.bn2.weight\n",
      "layers.6.3.bn2.bias\n",
      "layers.6.3.conv3.weight\n",
      "layers.6.3.bn3.weight\n",
      "layers.6.3.bn3.bias\n",
      "layers.6.4.conv1.weight\n",
      "layers.6.4.bn1.weight\n",
      "layers.6.4.bn1.bias\n",
      "layers.6.4.conv2.weight\n",
      "layers.6.4.bn2.weight\n",
      "layers.6.4.bn2.bias\n",
      "layers.6.4.conv3.weight\n",
      "layers.6.4.bn3.weight\n",
      "layers.6.4.bn3.bias\n",
      "layers.6.5.conv1.weight\n",
      "layers.6.5.bn1.weight\n",
      "layers.6.5.bn1.bias\n",
      "layers.6.5.conv2.weight\n",
      "layers.6.5.bn2.weight\n",
      "layers.6.5.bn2.bias\n",
      "layers.6.5.conv3.weight\n",
      "layers.6.5.bn3.weight\n",
      "layers.6.5.bn3.bias\n",
      "layers.7.0.conv1.weight\n",
      "layers.7.0.bn1.weight\n",
      "layers.7.0.bn1.bias\n",
      "layers.7.0.conv2.weight\n",
      "layers.7.0.bn2.weight\n",
      "layers.7.0.bn2.bias\n",
      "layers.7.0.conv3.weight\n",
      "layers.7.0.bn3.weight\n",
      "layers.7.0.bn3.bias\n",
      "layers.7.0.downsample.0.weight\n",
      "layers.7.0.downsample.1.weight\n",
      "layers.7.0.downsample.1.bias\n",
      "layers.7.1.conv1.weight\n",
      "layers.7.1.bn1.weight\n",
      "layers.7.1.bn1.bias\n",
      "layers.7.1.conv2.weight\n",
      "layers.7.1.bn2.weight\n",
      "layers.7.1.bn2.bias\n",
      "layers.7.1.conv3.weight\n",
      "layers.7.1.bn3.weight\n",
      "layers.7.1.bn3.bias\n",
      "layers.7.2.conv1.weight\n",
      "layers.7.2.bn1.weight\n",
      "layers.7.2.bn1.bias\n",
      "layers.7.2.conv2.weight\n",
      "layers.7.2.bn2.weight\n",
      "layers.7.2.bn2.bias\n",
      "layers.7.2.conv3.weight\n",
      "layers.7.2.bn3.weight\n",
      "layers.7.2.bn3.bias\n",
      "sa.q.weight\n",
      "sa.q.bias\n",
      "sa.k.weight\n",
      "sa.k.bias\n",
      "sa.v.weight\n",
      "sa.v.bias\n",
      "fc.weight\n"
     ]
    }
   ],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (sa): SA(\n",
       "    (q): Conv2d(2048, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (k): Conv2d(2048, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (v): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (ca): CA()\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=4096, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.s.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layers',\n",
       "              Sequential(\n",
       "                (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "                (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "                (4): Sequential(\n",
       "                  (0): Bottleneck(\n",
       "                    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                    (downsample): Sequential(\n",
       "                      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (1): Bottleneck(\n",
       "                    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (2): Bottleneck(\n",
       "                    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                )\n",
       "                (5): Sequential(\n",
       "                  (0): Bottleneck(\n",
       "                    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                    (downsample): Sequential(\n",
       "                      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (1): Bottleneck(\n",
       "                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (2): Bottleneck(\n",
       "                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (3): Bottleneck(\n",
       "                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                )\n",
       "                (6): Sequential(\n",
       "                  (0): Bottleneck(\n",
       "                    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                    (downsample): Sequential(\n",
       "                      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (1): Bottleneck(\n",
       "                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (2): Bottleneck(\n",
       "                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (3): Bottleneck(\n",
       "                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (4): Bottleneck(\n",
       "                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (5): Bottleneck(\n",
       "                    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                )\n",
       "                (7): Sequential(\n",
       "                  (0): Bottleneck(\n",
       "                    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                    (downsample): Sequential(\n",
       "                      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                  (1): Bottleneck(\n",
       "                    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (2): Bottleneck(\n",
       "                    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (relu): ReLU(inplace=True)\n",
       "                  )\n",
       "                )\n",
       "              )),\n",
       "             ('sa',\n",
       "              SA(\n",
       "                (q): Conv2d(2048, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (k): Conv2d(2048, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (v): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )),\n",
       "             ('ca', CA()),\n",
       "             ('gap', AdaptiveAvgPool2d(output_size=1)),\n",
       "             ('fc', Linear(in_features=4096, out_features=3, bias=False))])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((5,3,16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.view(x.shape[0],x.shape[1],-1).max(axis = 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.view(y.shape[0], -1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7859, 0.6851, 0.0262,  ..., 0.7031, 0.4171, 0.7241],\n",
       "          [0.3686, 0.9811, 0.4266,  ..., 0.4528, 0.1749, 0.2205],\n",
       "          [0.8201, 0.1084, 0.4113,  ..., 0.3064, 0.6119, 0.9901],\n",
       "          ...,\n",
       "          [0.4613, 0.1264, 0.0055,  ..., 0.3144, 0.2113, 0.5251],\n",
       "          [0.4014, 0.2377, 0.8019,  ..., 0.0080, 0.3427, 0.4396],\n",
       "          [0.2863, 0.3647, 0.5649,  ..., 0.4637, 0.8585, 0.9394]],\n",
       "\n",
       "         [[0.7501, 0.7567, 0.8688,  ..., 0.9142, 0.4708, 0.6067],\n",
       "          [0.7559, 0.3650, 0.6003,  ..., 0.4011, 0.6476, 0.7604],\n",
       "          [0.3049, 0.8584, 0.2857,  ..., 0.9180, 0.5321, 0.7875],\n",
       "          ...,\n",
       "          [0.8247, 0.8310, 0.6882,  ..., 0.1492, 0.1378, 0.1532],\n",
       "          [0.7901, 0.1637, 0.7826,  ..., 0.5542, 0.2824, 0.9822],\n",
       "          [0.2861, 0.2080, 0.3457,  ..., 0.7598, 0.3258, 0.6891]],\n",
       "\n",
       "         [[0.4746, 0.6576, 0.1199,  ..., 0.3280, 0.5491, 0.3118],\n",
       "          [0.2772, 0.4434, 0.3041,  ..., 0.9489, 0.2914, 0.0288],\n",
       "          [0.1541, 0.5944, 0.2737,  ..., 0.9891, 0.0549, 0.1583],\n",
       "          ...,\n",
       "          [0.3413, 0.7871, 0.2959,  ..., 0.0850, 0.4604, 0.0426],\n",
       "          [0.1014, 0.7563, 0.1772,  ..., 0.1599, 0.1669, 0.4640],\n",
       "          [0.2792, 0.6806, 0.6196,  ..., 0.7498, 0.7036, 0.2365]]],\n",
       "\n",
       "\n",
       "        [[[0.3536, 0.4860, 0.8228,  ..., 0.7942, 0.5751, 0.8667],\n",
       "          [0.0079, 0.2349, 0.3565,  ..., 0.0601, 0.8864, 1.0000],\n",
       "          [0.8126, 0.3281, 0.0499,  ..., 0.9805, 0.6948, 0.9194],\n",
       "          ...,\n",
       "          [0.8311, 0.0822, 0.4284,  ..., 0.3043, 0.8846, 0.9100],\n",
       "          [0.3178, 0.2258, 0.5527,  ..., 0.7270, 0.7889, 0.2730],\n",
       "          [0.0869, 0.3785, 0.1031,  ..., 0.9799, 0.4468, 0.7931]],\n",
       "\n",
       "         [[0.4852, 0.1839, 0.1958,  ..., 0.9375, 0.3177, 0.9378],\n",
       "          [0.9336, 0.7594, 0.8273,  ..., 0.8625, 0.2581, 0.3202],\n",
       "          [0.9258, 0.8976, 0.2449,  ..., 0.2547, 0.4545, 0.0108],\n",
       "          ...,\n",
       "          [0.3283, 0.3065, 0.0787,  ..., 0.4009, 0.2366, 0.2442],\n",
       "          [0.8329, 0.7546, 0.9367,  ..., 0.6392, 0.0600, 0.2281],\n",
       "          [0.7130, 0.5231, 0.1363,  ..., 0.1343, 0.5411, 0.4662]],\n",
       "\n",
       "         [[0.6550, 0.7158, 0.1991,  ..., 0.2858, 0.0772, 0.1694],\n",
       "          [0.2044, 0.3249, 0.8263,  ..., 0.5751, 0.3926, 0.1060],\n",
       "          [0.5640, 0.1941, 0.5520,  ..., 0.1153, 0.8161, 0.7671],\n",
       "          ...,\n",
       "          [0.5310, 0.9046, 0.9447,  ..., 0.7976, 0.4521, 0.0540],\n",
       "          [0.5463, 0.6912, 0.6395,  ..., 0.5481, 0.8145, 0.2692],\n",
       "          [0.2907, 0.1869, 0.5530,  ..., 0.9994, 0.5868, 0.9932]]],\n",
       "\n",
       "\n",
       "        [[[0.1256, 0.6068, 0.3090,  ..., 0.4781, 0.4429, 0.2440],\n",
       "          [0.8518, 0.2630, 0.0479,  ..., 0.5506, 0.2676, 0.5945],\n",
       "          [0.7040, 0.6419, 0.0981,  ..., 0.0757, 0.3417, 0.9273],\n",
       "          ...,\n",
       "          [0.1879, 0.5737, 0.1336,  ..., 0.4594, 0.0941, 0.8793],\n",
       "          [0.5529, 0.5164, 0.4335,  ..., 0.4198, 0.5138, 0.2070],\n",
       "          [0.3052, 0.9383, 0.7051,  ..., 0.2459, 0.1439, 0.1790]],\n",
       "\n",
       "         [[0.6062, 0.4775, 0.7762,  ..., 0.7367, 0.5380, 0.7624],\n",
       "          [0.4649, 0.4783, 0.0504,  ..., 0.1406, 0.4662, 0.6528],\n",
       "          [0.1940, 0.1522, 0.4954,  ..., 0.5738, 0.9232, 0.8683],\n",
       "          ...,\n",
       "          [0.3871, 0.4639, 0.1816,  ..., 0.7681, 0.4037, 0.2347],\n",
       "          [0.1385, 0.7224, 0.4408,  ..., 0.3020, 0.2549, 1.0000],\n",
       "          [0.2981, 0.8297, 0.6339,  ..., 0.9263, 0.2162, 0.8066]],\n",
       "\n",
       "         [[0.0152, 0.0888, 0.6341,  ..., 0.5422, 0.5919, 0.6802],\n",
       "          [0.2694, 0.5786, 0.4191,  ..., 0.0561, 0.5360, 0.4836],\n",
       "          [0.5242, 0.9050, 0.5669,  ..., 0.1310, 0.2685, 0.5237],\n",
       "          ...,\n",
       "          [0.1398, 0.6988, 0.5887,  ..., 0.0322, 0.4050, 0.0371],\n",
       "          [0.7838, 0.7829, 0.3831,  ..., 0.0970, 0.2955, 0.0234],\n",
       "          [0.5969, 0.1706, 0.3278,  ..., 0.9148, 0.2780, 0.5280]]],\n",
       "\n",
       "\n",
       "        [[[0.8767, 0.1696, 0.8419,  ..., 0.1241, 0.6081, 0.0108],\n",
       "          [0.5257, 0.4799, 0.2353,  ..., 0.9073, 0.0013, 0.7315],\n",
       "          [0.0451, 0.4273, 0.6545,  ..., 0.5933, 0.4753, 0.0330],\n",
       "          ...,\n",
       "          [0.9696, 0.6649, 0.3785,  ..., 0.6477, 0.2244, 0.3084],\n",
       "          [0.9423, 0.6802, 0.2808,  ..., 0.1139, 0.0524, 0.0145],\n",
       "          [0.0969, 0.2784, 0.2707,  ..., 0.9963, 0.2207, 0.3873]],\n",
       "\n",
       "         [[0.0477, 0.6922, 0.3728,  ..., 0.9182, 0.5644, 0.6420],\n",
       "          [0.0668, 0.7664, 0.7089,  ..., 0.1439, 0.7347, 0.7546],\n",
       "          [0.9222, 0.3901, 0.6407,  ..., 0.4123, 0.1742, 0.2012],\n",
       "          ...,\n",
       "          [0.7020, 0.8954, 0.5919,  ..., 0.7202, 0.7412, 0.8412],\n",
       "          [0.0979, 0.7298, 0.5746,  ..., 0.4809, 0.1170, 0.7443],\n",
       "          [0.5173, 0.4228, 0.6045,  ..., 0.8733, 0.8574, 0.5927]],\n",
       "\n",
       "         [[0.5053, 0.2993, 0.0344,  ..., 0.0345, 0.2937, 0.8778],\n",
       "          [0.8560, 0.2225, 0.7810,  ..., 0.6863, 0.6247, 0.0413],\n",
       "          [0.1557, 0.6672, 0.2921,  ..., 0.3143, 0.5586, 0.0260],\n",
       "          ...,\n",
       "          [0.9853, 0.1976, 0.7833,  ..., 0.9710, 0.3303, 0.3714],\n",
       "          [0.1317, 0.6572, 0.1101,  ..., 0.4301, 0.9801, 0.7385],\n",
       "          [0.0692, 0.4309, 0.6970,  ..., 0.7361, 0.8810, 0.8005]]],\n",
       "\n",
       "\n",
       "        [[[0.5382, 0.6830, 0.8630,  ..., 0.9409, 0.9282, 0.0522],\n",
       "          [0.5593, 0.9594, 0.9351,  ..., 0.9767, 0.9077, 0.4402],\n",
       "          [0.4711, 0.8968, 0.0151,  ..., 0.0276, 0.6023, 0.7534],\n",
       "          ...,\n",
       "          [0.3381, 0.9460, 0.7052,  ..., 0.7269, 0.8074, 0.9828],\n",
       "          [0.1701, 0.7596, 0.1547,  ..., 0.5197, 0.2678, 0.5270],\n",
       "          [0.7787, 0.2797, 0.2007,  ..., 0.6620, 0.7567, 0.1993]],\n",
       "\n",
       "         [[0.4593, 0.4120, 0.9370,  ..., 0.4535, 0.2356, 0.8142],\n",
       "          [0.4777, 0.5870, 0.4527,  ..., 0.5372, 0.5460, 0.6081],\n",
       "          [0.0315, 0.9637, 0.1076,  ..., 0.6824, 0.9039, 0.3926],\n",
       "          ...,\n",
       "          [0.5305, 0.0880, 0.5820,  ..., 0.6519, 0.9879, 0.0036],\n",
       "          [0.8894, 0.6838, 0.7704,  ..., 0.0557, 0.2938, 0.9265],\n",
       "          [0.4666, 0.0133, 0.0544,  ..., 0.1087, 0.4324, 0.7609]],\n",
       "\n",
       "         [[0.4583, 0.7759, 0.1744,  ..., 0.7649, 0.2318, 0.9377],\n",
       "          [0.4355, 0.3948, 0.4691,  ..., 0.7982, 0.4428, 0.2100],\n",
       "          [0.1467, 0.0868, 0.0341,  ..., 0.9319, 0.1423, 0.1480],\n",
       "          ...,\n",
       "          [0.4895, 0.5961, 0.5399,  ..., 0.1698, 0.2957, 0.6308],\n",
       "          [0.8219, 0.7482, 0.1457,  ..., 0.4343, 0.4814, 0.7385],\n",
       "          [0.7182, 0.4767, 0.5997,  ..., 0.0737, 0.9542, 0.6739]]]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7844, 0.6838, 0.0262,  ..., 0.7017, 0.4163, 0.7227],\n",
       "          [0.3679, 0.9791, 0.4257,  ..., 0.4519, 0.1746, 0.2201],\n",
       "          [0.8185, 0.1082, 0.4105,  ..., 0.3058, 0.6107, 0.9881],\n",
       "          ...,\n",
       "          [0.4604, 0.1262, 0.0055,  ..., 0.3138, 0.2109, 0.5241],\n",
       "          [0.4006, 0.2372, 0.8003,  ..., 0.0080, 0.3420, 0.4387],\n",
       "          [0.2857, 0.3640, 0.5638,  ..., 0.4628, 0.8568, 0.9375]],\n",
       "\n",
       "         [[0.7481, 0.7547, 0.8664,  ..., 0.9117, 0.4695, 0.6050],\n",
       "          [0.7539, 0.3640, 0.5987,  ..., 0.4000, 0.6458, 0.7583],\n",
       "          [0.3041, 0.8560, 0.2849,  ..., 0.9155, 0.5306, 0.7854],\n",
       "          ...,\n",
       "          [0.8225, 0.8287, 0.6863,  ..., 0.1487, 0.1374, 0.1528],\n",
       "          [0.7879, 0.1633, 0.7805,  ..., 0.5526, 0.2817, 0.9795],\n",
       "          [0.2854, 0.2075, 0.3448,  ..., 0.7577, 0.3249, 0.6872]],\n",
       "\n",
       "         [[0.4738, 0.6566, 0.1197,  ..., 0.3275, 0.5482, 0.3113],\n",
       "          [0.2768, 0.4427, 0.3036,  ..., 0.9473, 0.2909, 0.0287],\n",
       "          [0.1538, 0.5934, 0.2733,  ..., 0.9875, 0.0548, 0.1581],\n",
       "          ...,\n",
       "          [0.3408, 0.7858, 0.2954,  ..., 0.0848, 0.4596, 0.0426],\n",
       "          [0.1012, 0.7550, 0.1769,  ..., 0.1596, 0.1667, 0.4632],\n",
       "          [0.2787, 0.6795, 0.6186,  ..., 0.7486, 0.7025, 0.2361]]],\n",
       "\n",
       "\n",
       "        [[[0.3528, 0.4848, 0.8208,  ..., 0.7922, 0.5736, 0.8645],\n",
       "          [0.0079, 0.2343, 0.3556,  ..., 0.0600, 0.8841, 0.9975],\n",
       "          [0.8106, 0.3273, 0.0498,  ..., 0.9781, 0.6931, 0.9171],\n",
       "          ...,\n",
       "          [0.8290, 0.0820, 0.4274,  ..., 0.3035, 0.8824, 0.9077],\n",
       "          [0.3170, 0.2252, 0.5513,  ..., 0.7252, 0.7869, 0.2723],\n",
       "          [0.0867, 0.3775, 0.1028,  ..., 0.9774, 0.4457, 0.7912]],\n",
       "\n",
       "         [[0.4844, 0.1836, 0.1955,  ..., 0.9360, 0.3171, 0.9363],\n",
       "          [0.9321, 0.7582, 0.8260,  ..., 0.8611, 0.2577, 0.3197],\n",
       "          [0.9243, 0.8962, 0.2445,  ..., 0.2543, 0.4538, 0.0108],\n",
       "          ...,\n",
       "          [0.3278, 0.3060, 0.0786,  ..., 0.4002, 0.2363, 0.2438],\n",
       "          [0.8316, 0.7534, 0.9352,  ..., 0.6381, 0.0599, 0.2277],\n",
       "          [0.7118, 0.5222, 0.1360,  ..., 0.1341, 0.5403, 0.4654]],\n",
       "\n",
       "         [[0.6518, 0.7123, 0.1981,  ..., 0.2844, 0.0768, 0.1685],\n",
       "          [0.2034, 0.3233, 0.8223,  ..., 0.5723, 0.3907, 0.1055],\n",
       "          [0.5613, 0.1931, 0.5493,  ..., 0.1148, 0.8121, 0.7634],\n",
       "          ...,\n",
       "          [0.5284, 0.9001, 0.9401,  ..., 0.7937, 0.4499, 0.0538],\n",
       "          [0.5436, 0.6878, 0.6363,  ..., 0.5454, 0.8105, 0.2679],\n",
       "          [0.2893, 0.1860, 0.5503,  ..., 0.9945, 0.5839, 0.9884]]],\n",
       "\n",
       "\n",
       "        [[[0.1255, 0.6066, 0.3089,  ..., 0.4779, 0.4428, 0.2439],\n",
       "          [0.8516, 0.2629, 0.0479,  ..., 0.5505, 0.2676, 0.5944],\n",
       "          [0.7038, 0.6417, 0.0980,  ..., 0.0757, 0.3416, 0.9270],\n",
       "          ...,\n",
       "          [0.1878, 0.5735, 0.1335,  ..., 0.4593, 0.0940, 0.8790],\n",
       "          [0.5527, 0.5162, 0.4334,  ..., 0.4197, 0.5137, 0.2069],\n",
       "          [0.3051, 0.9381, 0.7049,  ..., 0.2458, 0.1438, 0.1790]],\n",
       "\n",
       "         [[0.6042, 0.4760, 0.7738,  ..., 0.7343, 0.5363, 0.7600],\n",
       "          [0.4634, 0.4767, 0.0502,  ..., 0.1402, 0.4647, 0.6507],\n",
       "          [0.1934, 0.1517, 0.4939,  ..., 0.5720, 0.9203, 0.8656],\n",
       "          ...,\n",
       "          [0.3859, 0.4624, 0.1810,  ..., 0.7656, 0.4024, 0.2339],\n",
       "          [0.1380, 0.7201, 0.4394,  ..., 0.3011, 0.2541, 0.9968],\n",
       "          [0.2971, 0.8271, 0.6318,  ..., 0.9233, 0.2155, 0.8040]],\n",
       "\n",
       "         [[0.0152, 0.0888, 0.6340,  ..., 0.5421, 0.5918, 0.6801],\n",
       "          [0.2694, 0.5785, 0.4191,  ..., 0.0561, 0.5359, 0.4835],\n",
       "          [0.5241, 0.9048, 0.5668,  ..., 0.1309, 0.2685, 0.5237],\n",
       "          ...,\n",
       "          [0.1398, 0.6987, 0.5886,  ..., 0.0322, 0.4049, 0.0371],\n",
       "          [0.7837, 0.7828, 0.3830,  ..., 0.0970, 0.2955, 0.0234],\n",
       "          [0.5968, 0.1706, 0.3277,  ..., 0.9147, 0.2779, 0.5279]]],\n",
       "\n",
       "\n",
       "        [[[0.8766, 0.1696, 0.8418,  ..., 0.1241, 0.6081, 0.0108],\n",
       "          [0.5256, 0.4799, 0.2352,  ..., 0.9072, 0.0013, 0.7314],\n",
       "          [0.0451, 0.4273, 0.6545,  ..., 0.5933, 0.4752, 0.0330],\n",
       "          ...,\n",
       "          [0.9696, 0.6648, 0.3784,  ..., 0.6477, 0.2244, 0.3084],\n",
       "          [0.9422, 0.6802, 0.2808,  ..., 0.1139, 0.0524, 0.0145],\n",
       "          [0.0969, 0.2784, 0.2706,  ..., 0.9963, 0.2206, 0.3873]],\n",
       "\n",
       "         [[0.0474, 0.6877, 0.3704,  ..., 0.9123, 0.5608, 0.6379],\n",
       "          [0.0664, 0.7615, 0.7044,  ..., 0.1430, 0.7299, 0.7497],\n",
       "          [0.9162, 0.3876, 0.6366,  ..., 0.4096, 0.1730, 0.1999],\n",
       "          ...,\n",
       "          [0.6975, 0.8896, 0.5881,  ..., 0.7156, 0.7364, 0.8357],\n",
       "          [0.0972, 0.7251, 0.5709,  ..., 0.4778, 0.1163, 0.7395],\n",
       "          [0.5140, 0.4200, 0.6006,  ..., 0.8677, 0.8519, 0.5889]],\n",
       "\n",
       "         [[0.5006, 0.2965, 0.0340,  ..., 0.0341, 0.2910, 0.8697],\n",
       "          [0.8482, 0.2204, 0.7738,  ..., 0.6800, 0.6190, 0.0410],\n",
       "          [0.1542, 0.6611, 0.2894,  ..., 0.3114, 0.5534, 0.0257],\n",
       "          ...,\n",
       "          [0.9762, 0.1957, 0.7761,  ..., 0.9621, 0.3273, 0.3680],\n",
       "          [0.1305, 0.6512, 0.1091,  ..., 0.4261, 0.9711, 0.7317],\n",
       "          [0.0686, 0.4270, 0.6906,  ..., 0.7294, 0.8729, 0.7932]]],\n",
       "\n",
       "\n",
       "        [[[0.5372, 0.6817, 0.8614,  ..., 0.9392, 0.9265, 0.0521],\n",
       "          [0.5583, 0.9576, 0.9334,  ..., 0.9749, 0.9060, 0.4394],\n",
       "          [0.4702, 0.8951, 0.0151,  ..., 0.0276, 0.6012, 0.7520],\n",
       "          ...,\n",
       "          [0.3374, 0.9443, 0.7039,  ..., 0.7256, 0.8059, 0.9810],\n",
       "          [0.1697, 0.7582, 0.1544,  ..., 0.5188, 0.2673, 0.5260],\n",
       "          [0.7773, 0.2792, 0.2004,  ..., 0.6608, 0.7553, 0.1989]],\n",
       "\n",
       "         [[0.4588, 0.4115, 0.9360,  ..., 0.4530, 0.2354, 0.8134],\n",
       "          [0.4772, 0.5864, 0.4522,  ..., 0.5367, 0.5454, 0.6074],\n",
       "          [0.0315, 0.9627, 0.1075,  ..., 0.6816, 0.9029, 0.3921],\n",
       "          ...,\n",
       "          [0.5299, 0.0879, 0.5814,  ..., 0.6512, 0.9868, 0.0036],\n",
       "          [0.8884, 0.6831, 0.7695,  ..., 0.0557, 0.2935, 0.9254],\n",
       "          [0.4661, 0.0133, 0.0543,  ..., 0.1085, 0.4320, 0.7601]],\n",
       "\n",
       "         [[0.4559, 0.7718, 0.1735,  ..., 0.7609, 0.2306, 0.9328],\n",
       "          [0.4332, 0.3928, 0.4666,  ..., 0.7940, 0.4405, 0.2089],\n",
       "          [0.1459, 0.0864, 0.0339,  ..., 0.9271, 0.1415, 0.1473],\n",
       "          ...,\n",
       "          [0.4869, 0.5929, 0.5371,  ..., 0.1689, 0.2942, 0.6275],\n",
       "          [0.8175, 0.7443, 0.1449,  ..., 0.4321, 0.4789, 0.7346],\n",
       "          [0.7144, 0.4742, 0.5965,  ..., 0.0733, 0.9492, 0.6704]]]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9980]],\n",
       "\n",
       "         [[0.9973]],\n",
       "\n",
       "         [[0.9984]]],\n",
       "\n",
       "\n",
       "        [[[0.9975]],\n",
       "\n",
       "         [[0.9984]],\n",
       "\n",
       "         [[0.9951]]],\n",
       "\n",
       "\n",
       "        [[[0.9997]],\n",
       "\n",
       "         [[0.9968]],\n",
       "\n",
       "         [[0.9998]]],\n",
       "\n",
       "\n",
       "        [[[0.9999]],\n",
       "\n",
       "         [[0.9935]],\n",
       "\n",
       "         [[0.9908]]],\n",
       "\n",
       "\n",
       "        [[[0.9981]],\n",
       "\n",
       "         [[0.9989]],\n",
       "\n",
       "         [[0.9948]]]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((10,3,5,6))\n",
    "y = torch.rand((10,3,6,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x,y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(1,3,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SA(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0,:,15,15] = z[0,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6844685310>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(z.numpy()[0].transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = z.clone()\n",
    "k = z.clone()\n",
    "v = z.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = q.view(1, 1, 3, -1).permute(0,1,3,2)\n",
    "query = query/torch.norm(query,dim=3,keepdim=True)\n",
    "key = k.view(1, 1, 3, -1)\n",
    "key = key/torch.norm(key, dim=2,keepdim=True)\n",
    "s = torch.matmul(query, key).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = torch.sigmoid(s)\n",
    "value = v.view(1, 3, -1)\n",
    "o = torch.bmm(value, alpha)\n",
    "o = o.view(1, 3, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(o.sum(dim=1).numpy()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(s[0][0].view(16,-1).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0][0].view(16,-1)[15][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
