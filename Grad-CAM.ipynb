{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "from torchvision import models, transforms\n",
    "from make_dloader import make_data\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import bbox_collate, MixedRandomSampler\n",
    "import transform as transf\n",
    "import yaml\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import numbers\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "import copy\n",
    "from model import ResNet50\n",
    "import time\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import random\n",
    "\n",
    "config = yaml.safe_load(open('./config.yaml'))\n",
    "dataset_means = json.load(open(config['dataset']['mean_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    \"\"\" Class for extracting activations and \n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.target_layers:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs += [x]\n",
    "        return outputs, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutputs():\n",
    "\n",
    "    def __init__(self, model, feature_module, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.feature_extractor = FeatureExtractor(self.feature_module, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            if module == self.feature_module:\n",
    "                target_activations, x = self.feature_extractor(x)\n",
    "            elif \"avgpool\" in name.lower():\n",
    "                x = module(x)\n",
    "                x = x.view(x.size(0),-1)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        \n",
    "        return target_activations, x\n",
    "\n",
    "\n",
    "def cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * (1-mask)), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)/255\n",
    "    cam = cam / np.max(cam)\n",
    "    return cam\n",
    "   \n",
    "def thresh(narray, threshold = 0.15, binary = False):\n",
    "    if binary:\n",
    "        return np.where(narray>threshold*np.max(narray), 1, 0)\n",
    "    return np.where(narray>threshold*np.max(narray), narray, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCam:\n",
    "    def __init__(self, model, feature_module, target_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = ModelOutputs(self.model, self.feature_module, target_layer_names)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def __call__(self, input, index=None):\n",
    "        if self.cuda:\n",
    "            features, output = self.extractor(input.cuda())\n",
    "        else:\n",
    "            features, output = self.extractor(input)\n",
    "        o = torch.sigmoid(output)\n",
    "        o = o.cpu().data.numpy()\n",
    "        if index == None:\n",
    "            o = np.where(o>0.5, 1., 0.)\n",
    "        label = o.sum(axis = 0)\n",
    "        #print(label)\n",
    "        label = np.where(label>o.shape[0]/2, 1., 0.)\n",
    "        cam_list = []\n",
    "        for i in range(len(label)):\n",
    "            if label[i] == 0:\n",
    "                cam_list.append(0)\n",
    "                continue\n",
    "                \n",
    "            one_hot = np.zeros_like(label)\n",
    "            one_hot[i] = 1.\n",
    "            one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "            if self.cuda:\n",
    "                one_hot = torch.sum(one_hot.cuda() * output)\n",
    "            else:\n",
    "                one_hot = torch.sum(one_hot * output)\n",
    "            \n",
    "            self.feature_module.zero_grad()\n",
    "            self.model.zero_grad()\n",
    "            one_hot.backward(retain_graph=True)\n",
    "\n",
    "            grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "            target = features[-1]\n",
    "            target = target.cpu().data.numpy() # 40,2048,16,16\n",
    "\n",
    "            weights = np.mean(grads_val, axis=(2, 3)) #40,2048\n",
    "            weights = weights[:,:,np.newaxis,np.newaxis] #40,2048,1,1\n",
    "            cam = np.zeros((target.shape[0], target.shape[2], target.shape[3]), dtype=np.float32) #40,16,16\n",
    "            target =  weights * target #40,2048,16,16\n",
    "            target = target.sum(axis=1) #40,16,16\n",
    "            target = np.maximum(target, 0)\n",
    "            T = np.zeros((input.shape[0],input.shape[2],input.shape[3]))\n",
    "            for b in range(input.shape[0]):\n",
    "                cam = cv2.resize(target[b], input.shape[2:])\n",
    "                cam = cam - np.min(cam)\n",
    "                cam = cam / np.max(cam)\n",
    "                T[b] = cam\n",
    "            cam_list.append(T)\n",
    "            \n",
    "        #if input.shape[0] == 1:\n",
    "        #    return cam_list\n",
    "        return label, cam_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=False)\n",
    "#model.fc = nn.Sequential( nn.Linear(in_features=2048, out_features=4, bias=True) )\n",
    "model = ResNet50()\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load(\"/data/unagi0/masaoka/resnet50_classify0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=model.resnet50, feature_module=model.resnet50.layer4, target_layer_names=[\"2\"], use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dataset_val, _ = make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "val_anomaly = dataset_val.with_annotation()\n",
    "#dataset_val = val_anomaly\n",
    "dataloader_val = DataLoader(dataset_val, num_workers=4, collate_fn=bbox_collate)\n",
    "unnormalize = transf.UnNormalize(dataset_means['mean'], dataset_means['std'])\n",
    "normalize = transf.Normalize(dataset_means['mean'], dataset_means['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss_r(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(loss_r, self).__init__()\n",
    "        \n",
    "    def forward(self, i, target):\n",
    "        loss = (target-i)**2\n",
    "        loss = loss.sum()\n",
    "        return 0.5*loss\n",
    "    \n",
    "class loss_l2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(loss_l2, self).__init__()\n",
    "    \n",
    "    def forward(self, i, rho = 1e-2):\n",
    "        loss = i**2\n",
    "        loss = loss.sum()\n",
    "        return 0.5*rho*loss\n",
    "    \n",
    "class loss_tv(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(loss_tv, self).__init__()\n",
    "    \n",
    "    def forward(self, i, target, rho = 1):\n",
    "        w, h = i.shape[0], i.shape[1]\n",
    "        lx = i[1:, :h-1] - target[:, :w-1, :h-1]\n",
    "        ly = i[:w-1, 1:] - target[:, :w-1, :h-1]\n",
    "        lx, ly = abs(lx), abs(ly)\n",
    "        loss = lx.sum()+ly.sum()\n",
    "        return rho*loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "        self.l2loss = loss_l2()\n",
    "        self.TVloss = loss_tv()\n",
    "        self.r_loss = loss_r()\n",
    "        \n",
    "    def forward(self, i, t):\n",
    "        #l2loss = loss_l2(i)\n",
    "        #TVloss = loss_tv(i,t)\n",
    "        #r_loss = loss_r(i,t)\n",
    "       # s = time.time()\n",
    "        l2loss = self.l2loss(i)\n",
    "        TVloss = self.TVloss(i,t)\n",
    "        r_loss = self.r_loss(i,t)\n",
    "        #e = time.time()\n",
    "        #print(f\"calc_loss {e-s}\")\n",
    "        loss = l2loss + TVloss + r_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converge_map(init, mask):\n",
    "    #init 512,512 ndarray ; mask b,512,512 ndarray\n",
    "    seq1 = iaa.Sequential([\n",
    "                    iaa.Affine(\n",
    "        rotate=iap.DiscreteUniform(-180,170)*(-1)\n",
    "                    )])\n",
    "    ia.seed(0)\n",
    "    mask_reconvert = torch.from_numpy(seq1(images=mask)) #b,512,512 tensor\n",
    "    mp = torch.from_numpy(init).requires_grad_(True) #512,512 tensor\n",
    "    #optimizer = optim.SGD([mp], lr = 1e-3)\n",
    "    #optimizer = optim.LBFGS([mp])\n",
    "    calc_loss = Loss()\n",
    "    calc_loss.cuda()\n",
    "    optimizer = optim.Adam([mp], lr = 5e-3)\n",
    "    losses = []\n",
    "    \"\"\"\n",
    "    for j in range(mask.shape[0]):\n",
    "        plt.imshow(mask_reconvert[j])\n",
    "        plt.show()\n",
    "    \"\"\"\n",
    "    for i in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        loss = calc_loss(mp.cuda(), mask_reconvert.cuda())\n",
    "        #s = time.time()\n",
    "        loss.backward()\n",
    "        #e = time.time()\n",
    "        #print(f\"backward {e-s}\")\n",
    "        optimizer.step()\n",
    "        #e2 = time.time()\n",
    "        #print(f\"optim {e2-e}\")\n",
    "        losses.append(loss)\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(losses)), losses, linestyle = '-', color = 'red', label = 'loss')\n",
    "    plt.xlabel('times')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    mp = mp.data.numpy()\n",
    "    return mp #512,512 ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_grad_cam(gcam, img):           #gcamはheatmapとlabelを出力するクラス\n",
    "    #img.shape=B,C,H,W　tensor\n",
    "    img = img.squeeze().numpy().transpose(1,2,0)  #512,512,3\n",
    "    b = 10\n",
    "    img = np.tile(img,(b,1,1,1)) #b,512,512,3\n",
    "    seq = iaa.Sequential([\n",
    "                    iaa.Affine(\n",
    "        rotate=iap.DiscreteUniform(-180, 179)\n",
    "                    )])\n",
    "    ia.seed(0)\n",
    "    img = seq(images=img)\n",
    "    img = torch.from_numpy(img)\n",
    "    labels, masks = grad_cam(img.permute(0,3,1,2), None) #label [1,0,0,0] masks [(40,512,512), 0, (40,512,512), 0]\n",
    "    maps = []\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == 0:\n",
    "            maps.append(0)\n",
    "            continue\n",
    "        elif i == len(labels)-1:\n",
    "            continue\n",
    "        else:\n",
    "            init_map = masks[i][0] #512,512\n",
    "            mp = converge_map(init_map, masks[i])\n",
    "            #plt.imshow(mp)\n",
    "            #plt.show()\n",
    "            #print(mp)\n",
    "            maps.append(mp[np.newaxis,:,:])\n",
    "    \n",
    "    return maps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap2box(heatmap, img=0, threshold = 0.5):\n",
    "    # img 512,512,3 ndarray,      heatmap  1,512,512 ndarray\n",
    "    if not isinstance(img, numbers.Number):\n",
    "        image = img.copy()\n",
    "    heatmap = thresh(heatmap, threshold = threshold)\n",
    "    heatmap = heatmap[0]\n",
    "    heatmap = np.uint8(255*heatmap)\n",
    "    label = cv2.connectedComponentsWithStats(heatmap)\n",
    "    n = label[0] - 1\n",
    "    data = np.delete(label[2], 0, 0)\n",
    "    boxes = torch.tensor([])\n",
    "    for i in range(n):\n",
    "    # 各オブジェクトの外接矩形を赤枠で表示\n",
    "        x0 = data[i][0]\n",
    "        y0 = data[i][1]\n",
    "        x1 = data[i][0] + data[i][2]\n",
    "        y1 = data[i][1] + data[i][3]\n",
    "        if boxes.shape[0] == 0:\n",
    "            boxes = torch.tensor([[x0,y0,x1,y1]])\n",
    "        else:\n",
    "            torch.cat((boxes, torch.tensor([[x0,y0,x1,y1]])), dim=0)\n",
    "        score = threshold\n",
    "        if not isinstance(img, numbers.Number):\n",
    "            cv2.rectangle(image, (x0, y0), (x1, y1), (255, 255, 0), thickness = 4)\n",
    "    #if not isinstance(img, numbers.Number):\n",
    "    #    plt.imshow(image)\n",
    "    #    plt.show()\n",
    "    return boxes, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1099.   77.   75.] [2. 0. 0.] [12.  0.  1.] [7770. 7770. 7770.]\n"
     ]
    }
   ],
   "source": [
    "#通常の評価　マスクなし\n",
    "\n",
    "def draw_caption(image, box, caption):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)\n",
    "threshold= .5\n",
    "gt, tpa, fpa, tna = np.zeros(3),np.zeros(3),np.zeros(3),np.zeros(3)\n",
    "for idx, data in enumerate(dataloader_val): \n",
    "    for i in range(len(data[\"bboxes\"][0])):\n",
    "        x1 = int(data[\"bboxes\"][0][i][0])\n",
    "        y1 = int(data[\"bboxes\"][0][i][1])\n",
    "        x2 = int(data[\"bboxes\"][0][i][2])\n",
    "        y2 = int(data[\"bboxes\"][0][i][3])\n",
    "        label_name = dataset_val.labels[int(data[\"labels\"][0][i])]\n",
    "        #print(label_name)\n",
    "    \n",
    "    masks = grad_cam(data[\"img\"], None)\n",
    "    target = np.zeros(3)\n",
    "    if len(data[\"bboxes\"][0]) != 0:\n",
    "        target[int(data[\"labels\"][0][0])] = 1\n",
    "    output = masks[0]\n",
    "    \n",
    "    \n",
    "    gt += target\n",
    "    tp = (output * target)\n",
    "    fp = (output * (1 - target))\n",
    "    tn = np.all((1 - output) * (1 - target))\n",
    "    tpa += tp\n",
    "    fpa += fp\n",
    "    tna += tn\n",
    "    #break\n",
    "    #if isinstance(masks[2],numbers.Number):\n",
    "    #        continue\n",
    "    #masksa = augmented_grad_cam(grad_cam, data[\"img\"]) \n",
    "    masks = masks[1]\n",
    "    data['img'] = data['img'].squeeze(dim=0).numpy()\n",
    "    img = unnormalize(data)['img'].copy() \n",
    "    img[img<0] = 0\n",
    "    img[img>255] = 255\n",
    "    flag = 0\n",
    "    for num, mask in enumerate(masks):\n",
    "        if isinstance(mask,numbers.Number):\n",
    "            flag += 1\n",
    "            \"\"\"if flag == 3:\n",
    "                print(\"Normal\")\"\"\"\n",
    "            continue\n",
    "        \"\"\"print(\"----------------------------------------\")\n",
    "        print(\"Grad-CAM\")\n",
    "        if num == 0:\n",
    "            print(\"torose lesion\")\n",
    "        elif num == 1:\n",
    "            print(\"vascular lesion\")\n",
    "        elif num == 2:\n",
    "            print(\"ulcer\")\"\"\"\n",
    "        #mask 1,512,512\n",
    "        #heatmap2box(mask, img=img, threshold = threshold)\n",
    "        mask_thresh = thresh(mask, threshold = threshold)\n",
    "        grad1 = cam_on_image(img, mask_thresh[0])\n",
    "        heatmap2box(mask, img=grad1, threshold = threshold)\n",
    "        #plt.imshow(grad1)\n",
    "        #plt.show()\n",
    "        grad1 = cv2.cvtColor(grad1, cv2.COLOR_BGR2RGB)\n",
    "        #cv2.imwrite(f\"/data/unagi0/masaoka/w_o_mask_grad_cam/{idx}_{num}.png\", np.uint8(255*grad1))\n",
    "    #print(\"------------------------------------\")\n",
    "    \"\"\"print(\"Augmented Grad-CAM\")\n",
    "    for num, mask in enumerate(masksa):\n",
    "        if isinstance(mask,numbers.Number):\n",
    "            continue\n",
    "        if num == 0:\n",
    "            print(\"torose lesion\")\n",
    "        elif num == 1:\n",
    "            print(\"vascular lesion\")\n",
    "        elif num == 2:\n",
    "            print(\"ulcer\")\n",
    "        else:\n",
    "            print(\"Normal\")\n",
    "        #heatmap2box(mask, img=img, threshold = threshold)\n",
    "        mask_thresh = thresh(mask, threshold = threshold)\n",
    "        grad = cam_on_image(img, mask_thresh[0])\n",
    "        heatmap2box(mask, img=grad, threshold = threshold)\n",
    "        plt.imshow(grad)\n",
    "        plt.show()\"\"\"\n",
    "    #print(\"-------------------------------------\")\n",
    "    #print(\"Ground Truth\")\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    label = 3\n",
    "    for i in range(len(data[\"bboxes\"][0])):\n",
    "        x1 = int(data[\"bboxes\"][0][i][0])\n",
    "        y1 = int(data[\"bboxes\"][0][i][1])\n",
    "        x2 = int(data[\"bboxes\"][0][i][2])\n",
    "        y2 = int(data[\"bboxes\"][0][i][3])\n",
    "        label_name = dataset_val.labels[int(data[\"labels\"][0][i])]\n",
    "        draw_caption(img, (x1, y1, x2, y2), label_name)\n",
    "        if label_name == \"ulcer\":\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2) #緑\n",
    "        else:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2) #赤\n",
    "        label = int(data[\"labels\"][0][i])\n",
    "        #print(label_name)\n",
    "        \n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #cv2.imwrite(f\"/data/unagi0/masaoka/w_o_mask_normal/{idx}_{label}.png\", img)\n",
    "    \n",
    "print(tpa,gt-tpa,fpa,tna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1087.,   19.,   72.]),\n",
       " array([14., 58.,  3.]),\n",
       " array([504.,  26.,  12.]),\n",
       " array([7296., 7296., 7296.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#腫瘍にマスク、正常画像はランダムにマスク\n",
    "def draw_caption(image, box, caption):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)\n",
    "threshold= .5\n",
    "gt, tpa, fpa, tna = np.zeros(3),np.zeros(3),np.zeros(3),np.zeros(3)\n",
    "all_masks = []\n",
    "size = config[\"inputsize\"]\n",
    "for idx, data in enumerate(dataloader_val): \n",
    "    mask = torch.ones((size,size))\n",
    "    flag = -1\n",
    "    for i in range(len(data[\"bboxes\"][0])):\n",
    "        flag = 1\n",
    "        x1 = int(data[\"bboxes\"][0][i][0])\n",
    "        y1 = int(data[\"bboxes\"][0][i][1])\n",
    "        x2 = int(data[\"bboxes\"][0][i][2])\n",
    "        y2 = int(data[\"bboxes\"][0][i][3])\n",
    "        mask[y1:y2,x1:x2] = 0\n",
    "        inv_mask = 1 - mask\n",
    "        if (y2-y1)*(x2-x1) < size*size/4:\n",
    "            all_masks.append(mask)\n",
    "        label_name = dataset_val.labels[int(data[\"labels\"][0][i])]\n",
    "        #print(label_name)\n",
    "    if flag != 1:\n",
    "        mask = random.choice(all_masks)\n",
    "        inv_mask = 1 - mask\n",
    "        \n",
    "    blur = gaussian_filter(data[\"img\"]*inv_mask,10)\n",
    "    image = data[\"img\"]*mask\n",
    "    data[\"img\"] = image + blur\n",
    "    masks = grad_cam(data[\"img\"], None)\n",
    "    target = np.zeros(3)\n",
    "    if len(data[\"bboxes\"][0]) != 0:\n",
    "        target[int(data[\"labels\"][0][0])] = 1\n",
    "    output = masks[0]\n",
    "    \n",
    "    \n",
    "    gt += target\n",
    "    tp = (output * target)\n",
    "    fp = (output * (1 - target))\n",
    "    tn = np.all((1 - output) * (1 - target))\n",
    "    tpa += tp\n",
    "    fpa += fp\n",
    "    tna += tn\n",
    "    #break\n",
    "    #if isinstance(masks[2],numbers.Number):\n",
    "    #        continue\n",
    "    #masksa = augmented_grad_cam(grad_cam, data[\"img\"]) \n",
    "    masks = masks[1]\n",
    "    data['img'] = data['img'].squeeze(dim=0).numpy()\n",
    "    img = unnormalize(data)['img'].copy() \n",
    "    img[img<0] = 0\n",
    "    img[img>255] = 255\n",
    "    flag = 0\n",
    "    for num, mask in enumerate(masks):\n",
    "        if isinstance(mask,numbers.Number):\n",
    "            flag += 1\n",
    "            \"\"\"if flag == 3:\n",
    "                print(\"Normal\")\"\"\"\n",
    "            continue\n",
    "        #print(\"----------------------------------------\")\n",
    "        #print(\"Grad-CAM\")\n",
    "        \"\"\"if num == 0:\n",
    "            print(\"torose lesion\")\n",
    "        elif num == 1:\n",
    "            print(\"vascular lesion\")\n",
    "        elif num == 2:\n",
    "            print(\"ulcer\")\"\"\"\n",
    "        #mask 1,512,512\n",
    "        #heatmap2box(mask, img=img, threshold = threshold)\n",
    "        mask_thresh = thresh(mask, threshold = threshold)\n",
    "        grad1 = cam_on_image(img, mask_thresh[0])\n",
    "        heatmap2box(mask, img=grad1, threshold = threshold)\n",
    "        grad1 = cv2.cvtColor(grad1, cv2.COLOR_BGR2RGB)\n",
    "        #cv2.imwrite(f\"/data/unagi0/masaoka/w_mask_grad_cam/{idx}_{num}.png\", np.uint8(255*grad1))\n",
    "    #print(\"------------------------------------\")\n",
    "    \"\"\"print(\"Augmented Grad-CAM\")\n",
    "    for num, mask in enumerate(masksa):\n",
    "        if isinstance(mask,numbers.Number):\n",
    "            continue\n",
    "        if num == 0:\n",
    "            print(\"torose lesion\")\n",
    "        elif num == 1:\n",
    "            print(\"vascular lesion\")\n",
    "        elif num == 2:\n",
    "            print(\"ulcer\")\n",
    "        else:\n",
    "            print(\"Normal\")\n",
    "        #heatmap2box(mask, img=img, threshold = threshold)\n",
    "        mask_thresh = thresh(mask, threshold = threshold)\n",
    "        grad = cam_on_image(img, mask_thresh[0])\n",
    "        heatmap2box(mask, img=grad, threshold = threshold)\n",
    "        plt.imshow(grad)\n",
    "        plt.show()\"\"\"\n",
    "    #print(\"-------------------------------------\")\n",
    "    #print(\"Ground Truth\")\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    label = 3\n",
    "    for i in range(len(data[\"bboxes\"][0])):\n",
    "        x1 = int(data[\"bboxes\"][0][i][0])\n",
    "        y1 = int(data[\"bboxes\"][0][i][1])\n",
    "        x2 = int(data[\"bboxes\"][0][i][2])\n",
    "        y2 = int(data[\"bboxes\"][0][i][3])\n",
    "        label_name = dataset_val.labels[int(data[\"labels\"][0][i])]\n",
    "        draw_caption(img, (x1, y1, x2, y2), label_name)\n",
    "        if label_name == \"ulcer\":\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2) #緑\n",
    "        else:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2) #赤\n",
    "        label = int(data[\"labels\"][0][i])\n",
    "        \n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #cv2.imwrite(f\"/data/unagi0/masaoka/w_mask_normal/{idx}_{label}.png\", img)\n",
    "    \n",
    "print(tpa,gt-tpa,fpa,tna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ　マスクなし TP(異常を異常と判断)[3752.  444.  322.] FN(異常を正常と判断)[18.  0.  0.] \n",
    "#FP(正常を異常と判断)[24. 34.  2.] TN(正常を正常と判断)[27011. 27011. 27011.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ　マスクあり　　TP(異常部を削除して異常と判断)[2740.  182.  317.]  　FN(異常部を削除して正常と判断)[1030.  262.    5.]　\n",
    "# FP(真に正常を異常と判断)[488.  88. 260.] 　TN(真に正常を正常と判断)[26620. 26620. 26620.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#異常部分のみ切り出し　(異常部を見て異常と判断)[3572.  426.  269.] (異常部を見て正常と判断)[198.  18.  53.] \n",
    "#(正常切り出しを異常と判断)[1672.  299.  496.]　(正常切り出しを正常と判断)[24742. 24742. 24742.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dataset_val, _ = make_data()\n",
    "val_anomaly = dataset_val.with_annotation()\n",
    "#dataset_val = val_anomaly\n",
    "dataloader_val = DataLoader(dataset_val, num_workers=3, collate_fn=bbox_collate)\n",
    "unnormalize = transf.UnNormalize(dataset_means['mean'], dataset_means['std'])\n",
    "normalize = transf.Normalize(dataset_means['mean'], dataset_means['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#腫瘍を切り出し表示、正常画像はランダムに切り出し表示\n",
    "import random\n",
    "def draw_caption(image, box, caption):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)\n",
    "threshold= .5\n",
    "gt, tpa, fpa, tna = np.zeros(3),np.zeros(3),np.zeros(3),np.zeros(3)\n",
    "all_masks = []\n",
    "for idx, data in enumerate(dataloader_val): \n",
    "    mask = torch.zeros((256,256))\n",
    "    flag = 0\n",
    "    for i in range(len(data[\"bboxes\"][0])):\n",
    "        flag = 1\n",
    "        x1 = int(data[\"bboxes\"][0][i][0])\n",
    "        y1 = int(data[\"bboxes\"][0][i][1])\n",
    "        x2 = int(data[\"bboxes\"][0][i][2])\n",
    "        y2 = int(data[\"bboxes\"][0][i][3])\n",
    "        mask[y1:y2,x1:x2] = 1\n",
    "        inv_mask = 1 - mask\n",
    "        if (y2-y1)*(x2-x1) < size*size/4:\n",
    "            all_masks.append(mask) \n",
    "        label_name = dataset_val.labels[int(data[\"labels\"][0][i])]\n",
    "        #print(label_name)\n",
    "    if flag ==0:\n",
    "        mask = random.choice(all_masks)\n",
    "        inv_mask = 1 - mask\n",
    "    blur = gaussian_filter(data[\"img\"]*inv_mask,10)\n",
    "    image = data[\"img\"]*mask\n",
    "    data[\"img\"] = image + blur\n",
    "    masks = grad_cam(data[\"img\"], None)\n",
    "    target = np.zeros(3)\n",
    "    if len(data[\"bboxes\"][0]) != 0:\n",
    "        target[int(data[\"labels\"][0][0])] = 1\n",
    "    output = masks[0]\n",
    "    \n",
    "    \n",
    "    gt += target\n",
    "    tp = (output * target)\n",
    "    fp = (output * (1 - target))\n",
    "    tn = np.all((1 - output) * (1 - target))\n",
    "    tpa += tp\n",
    "    fpa += fp\n",
    "    tna += tn\n",
    "    #break\n",
    "    #if isinstance(masks[2],numbers.Number):\n",
    "    #        continue\n",
    "    #masksa = augmented_grad_cam(grad_cam, data[\"img\"]) \n",
    "    masks = masks[1]\n",
    "    data['img'] = data['img'].squeeze(dim=0).numpy()\n",
    "    img = unnormalize(data)['img'].copy() \n",
    "    img[img<0] = 0\n",
    "    img[img>255] = 255\n",
    "    flag = 0\n",
    "    for num, mask in enumerate(masks):\n",
    "        if isinstance(mask,numbers.Number):\n",
    "            flag += 1\n",
    "            \"\"\"if flag == 3:\n",
    "                print(\"Normal\")\"\"\"\n",
    "            continue\n",
    "        \"\"\"print(\"----------------------------------------\")\n",
    "        print(\"Grad-CAM\")\n",
    "        if num == 0:\n",
    "            print(\"torose lesion\")\n",
    "        elif num == 1:\n",
    "            print(\"vascular lesion\")\n",
    "        elif num == 2:\n",
    "            print(\"ulcer\")\"\"\"\n",
    "        #mask 1,512,512\n",
    "        #heatmap2box(mask, img=img, threshold = threshold)\n",
    "        mask_thresh = thresh(mask, threshold = threshold)\n",
    "        grad1 = cam_on_image(img, mask_thresh[0])\n",
    "        heatmap2box(mask, img=grad1, threshold = threshold)\n",
    "        grad1 = cv2.cvtColor(grad1, cv2.COLOR_BGR2RGB)\n",
    "        #cv2.imwrite(f\"/data/unagi0/masaoka/tumor_only_grad_cam/{idx}_{num}.png\", np.uint8(255*grad1))\n",
    "    #print(\"------------------------------------\")\n",
    "    \"\"\"print(\"Augmented Grad-CAM\")\n",
    "    for num, mask in enumerate(masksa):\n",
    "        if isinstance(mask,numbers.Number):\n",
    "            continue\n",
    "        if num == 0:\n",
    "            print(\"torose lesion\")\n",
    "        elif num == 1:\n",
    "            print(\"vascular lesion\")\n",
    "        elif num == 2:\n",
    "            print(\"ulcer\")\n",
    "        else:\n",
    "            print(\"Normal\")\n",
    "        #heatmap2box(mask, img=img, threshold = threshold)\n",
    "        mask_thresh = thresh(mask, threshold = threshold)\n",
    "        grad = cam_on_image(img, mask_thresh[0])\n",
    "        heatmap2box(mask, img=grad, threshold = threshold)\n",
    "        plt.imshow(grad)\n",
    "        plt.show()\"\"\"\n",
    "    #print(\"-------------------------------------\")\n",
    "    #print(\"Ground Truth\")\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    label = 3\n",
    "    for i in range(len(data[\"bboxes\"][0])):\n",
    "        x1 = int(data[\"bboxes\"][0][i][0])\n",
    "        y1 = int(data[\"bboxes\"][0][i][1])\n",
    "        x2 = int(data[\"bboxes\"][0][i][2])\n",
    "        y2 = int(data[\"bboxes\"][0][i][3])\n",
    "        label_name = dataset_val.labels[int(data[\"labels\"][0][i])]\n",
    "        draw_caption(img, (x1, y1, x2, y2), label_name)\n",
    "        if label_name == \"ulcer\":\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2) #緑\n",
    "        else:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2) #赤\n",
    "        label = int(data[\"labels\"][0][i])\n",
    "        \n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #cv2.imwrite(f\"/data/unagi0/masaoka/tumor_only_normal/{idx}_{label}.png\", img)\n",
    "    \n",
    "print(tpa,gt-tpa,fpa,tna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid data [799.  70.  75.] [21. 24.  1.] [188. 334.  72.] [6979. 6979. 6979.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid data 異常部を削除、正常画像はランダムに削除　[522.   2.  59.] [298.  92.  17.] [911. 381.  23.] [6213. 6213. 6213.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid data 異常画像のみ切り出し、正常画像はランダムに切り出し　[791.  83.  32.] [29. 11. 44.] [1392.  310.   11.] [5705. 5705. 5705.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ　マスクなし TP(異常を異常と判断)[799.  70.  75.]  FN(異常を正常と判断)[21. 24.  1.]\n",
    "#FP(正常を異常と判断)[188. 334.  72.]  TN(正常を正常と判断)[6979. 6979. 6979.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データ　マスクあり　　TP(異常部を削除して異常と判断)[522.   2.  59.] 　FN(異常部を削除して正常と判断)[298.  92.  17.]　\n",
    "# FP(真に正常を異常と判断) [911. 381.  23.]　TN(真に正常を正常と判断)[6213. 6213. 6213.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#異常部分のみ切り出し　(異常部を見て異常と判断)[791.  83.  32.]  (異常部を見て正常と判断)[29. 11. 44.] \n",
    "#(正常切り出しを異常と判断)[1392.  310.   11.] 　(正常切り出しを正常と判断)[5705. 5705. 5705.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97439024 0.74468085 0.98684211] [0.97376866 0.95432791 0.98978868]\n"
     ]
    }
   ],
   "source": [
    "tp = np.array([799. , 70. , 75.])\n",
    "fn = np.array([21. ,24.  ,1.] )\n",
    "fp = np.array([188., 334. , 72.])\n",
    "tn = np.array([6979. ,6979. ,6979.])\n",
    "recall = tp/(tp+fn)\n",
    "s = tn/(tn+fp)\n",
    "print(recall, s)\n",
    "#精度はバランスが取れてとても良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63780488 0.03191489 0.85526316] [0.8721224  0.9422202  0.99631174]\n"
     ]
    }
   ],
   "source": [
    "tp = np.array([523.   ,3.  ,65.])\n",
    "fn = np.array([297.  ,91.  ,11.] )\n",
    "fp = np.array([911., 381. , 23.])\n",
    "tn = np.array([6213., 6213., 6213.])\n",
    "recall = tp/(tp+fn)\n",
    "s = tn/(tn+fp)\n",
    "print(recall, s)\n",
    "#異常部分を消した元異常画像が誤って異常と検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92926829 0.76595745 0.94736842]\n"
     ]
    }
   ],
   "source": [
    "tp = np.array([762.,  72. , 72.])\n",
    "fn = np.array([58. ,22.  ,4.] )\n",
    "fp = np.array([ 12.,  57. ,180.])\n",
    "#tn += np.array([6979. ,6979. ,6979.])\n",
    "recall = tp/(tp+fn)\n",
    "print(recall)\n",
    "#異常部分だけ切り出して検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annot': array([[284., 330., 470., 485.,   0.]]),\n",
       " 'bboxes': array([[284., 330., 470., 485.]], dtype=float32),\n",
       " 'labels': array([0])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.load_annotations(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
