{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "import json\n",
    "import torch\n",
    "import transform as transf\n",
    "from torchvision.transforms import Compose\n",
    "import yaml\n",
    "from dataset import MedicalBboxDataset\n",
    "from model import ResNet50\n",
    "import numpy as np\n",
    "from utils import bbox_collate, data2target, calc_confusion_matrix, draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_coco_weak(val, threshold=0.05):\n",
    "    config = yaml.safe_load(open('./config.yaml'))\n",
    "    dataset_means = json.load(open(config['dataset']['mean_file']))\n",
    "    dataset_all = MedicalBboxDataset(\n",
    "        config['dataset']['annotation_file'],\n",
    "        config['dataset']['image_root'])\n",
    "    if 'class_integration' in config['dataset']:\n",
    "        dataset_all = dataset_all.integrate_classes(\n",
    "            config['dataset']['class_integration']['new'],\n",
    "            config['dataset']['class_integration']['map'])\n",
    "    \n",
    "    transform = Compose([\n",
    "        transf.ToFixedSize([config['inputsize']] * 2),  # inputsize x inputsizeの画像に変換\n",
    "        transf.Normalize(dataset_means['mean'], dataset_means['std']),\n",
    "        transf.HWCToCHW()\n",
    "        ])\n",
    "\n",
    "    dataset = dataset_all.split(val, config['dataset']['split_file'])\n",
    "    dataset.set_transform(transform)\n",
    "    \n",
    "    model = ResNet50()\n",
    "    model.load_state_dict(torch.load(f\"/data/unagi0/masaoka/wsod/model/resnet50_classify{val}.pt\"))\n",
    "    \n",
    "\n",
    "    results = []\n",
    "    image_ids = []\n",
    "    for index in range(len(dataset)):\n",
    "        data = dataset[index]\n",
    "        data['img'] = torch.from_numpy(data['img']) #.permute(2, 0, 1)\n",
    "        # run network\n",
    "        if torch.cuda.is_available():\n",
    "            #scores, labels, boxes = model(data['img'].cuda().float().unsqueeze(dim=0))\n",
    "            scores, labels, boxes = model(data['img'].unsqueeze(0).float(), e=True, aug=False)\n",
    "        else:\n",
    "            scores, labels, boxes = model(data['img'].float().unsqueeze(dim=0), e=True, aug=True)\n",
    "        scores = scores.cpu()\n",
    "        labels = labels.cpu()\n",
    "        boxes  = boxes.cpu()\n",
    "\n",
    "        \n",
    "\n",
    "        if boxes.shape[0] > 0:\n",
    "            # change to (x, y, w, h) (MS COCO standard)\n",
    "            boxes[:, 2] -= boxes[:, 0]\n",
    "            boxes[:, 3] -= boxes[:, 1]\n",
    "\n",
    "            # compute predicted labels and scores\n",
    "            #for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            for box_id in range(boxes.shape[0]):\n",
    "                score = float(scores[box_id])\n",
    "                label = int(labels[box_id])\n",
    "                box = boxes[box_id, :]\n",
    "                \n",
    "\n",
    "                # scores are sorted, so we can break\n",
    "                if score < threshold:\n",
    "                    break\n",
    "\n",
    "                # append detection for each positively labeled class\n",
    "                image_result = {\n",
    "                        'image_id'    : dataset.imgids[index],\n",
    "                        'category_id' : dataset.label_to_coco_label(label),\n",
    "                        'score'       : float(score),\n",
    "                        'bbox'        : box.tolist(),\n",
    "                    }\n",
    "\n",
    "                # append detection to results\n",
    "                results.append(image_result)\n",
    "\n",
    "        # append image to list of processed images\n",
    "        image_ids.append(dataset.imgids[index])\n",
    "\n",
    "        # print progress\n",
    "        print('{}/{}'.format(index+1, len(dataset)), end='\\r')\n",
    "\n",
    "    if not len(results):\n",
    "            print(\"error\")\n",
    "            return\n",
    "        # write output\n",
    "    json.dump(results, open(f'/data/unagi0/masaoka/wsod/result_bbox/result{val}.json', 'w'), indent=4)\n",
    "\n",
    "    # load results in COCO evaluation tool\n",
    "    coco_true = dataset.coco\n",
    "    coco_pred = coco_true.loadRes(f'/data/unagi0/masaoka/wsod/result_bbox/result{val}.json')\n",
    "\n",
    "    # run COCO evaluation\n",
    "    coco_eval = COCOeval(coco_true, coco_pred, 'bbox')\n",
    "    coco_eval.params.imgIds = image_ids\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
      "loading annotations into memory...\n",
      "Done (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.37s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.69s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "6129/8369\r"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    evaluate_coco_weak(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classify(val, threshold=0.05):\n",
    "    config = yaml.safe_load(open('./config.yaml'))\n",
    "    dataset_means = json.load(open(config['dataset']['mean_file']))\n",
    "    dataset_all = MedicalBboxDataset(\n",
    "        config['dataset']['annotation_file'],\n",
    "        config['dataset']['image_root'])\n",
    "    if 'class_integration' in config['dataset']:\n",
    "        dataset_all = dataset_all.integrate_classes(\n",
    "            config['dataset']['class_integration']['new'],\n",
    "            config['dataset']['class_integration']['map'])\n",
    "    \n",
    "    transform = Compose([\n",
    "        transf.ToFixedSize([config['inputsize']] * 2),  # inputsize x inputsizeの画像に変換\n",
    "        transf.Normalize(dataset_means['mean'], dataset_means['std']),\n",
    "        transf.HWCToCHW()\n",
    "        ])\n",
    "\n",
    "    dataset = dataset_all.split(val, config['dataset']['split_file'])\n",
    "    dataset.set_transform(transform)\n",
    "    dataloader_val = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=False, \n",
    "                                                num_workers=4, collate_fn=bbox_collate)\n",
    "    model = ResNet50()\n",
    "    model.load_state_dict(torch.load(f\"/data/unagi0/masaoka/wsod/model/resnet50_classify1.pt\"))\n",
    "    ite = 0\n",
    "    gt = [0,0,0,0]\n",
    "    tpa = np.zeros(3)\n",
    "    fpa = np.zeros(3)\n",
    "    tna = 0\n",
    "    fna = np.zeros(3)\n",
    "    with torch.no_grad():\n",
    "        for i, d in enumerate(dataloader_val):\n",
    "            scores = torch.sigmoid(model(d['img'].cuda().float()))\n",
    "            output = scores.cpu().data.numpy()\n",
    "            output = np.where(output>0.5,1,0)\n",
    "            target, n, t, v, u = data2target(d, torch.from_numpy(output))\n",
    "            target = target.cpu().data.numpy()\n",
    "            gt = np.array([n,t,v,u])\n",
    "            tp, fp, fn, tn = calc_confusion_matrix(output, target, gt)\n",
    "            tpa += tp\n",
    "            fpa += fp\n",
    "            fna += fn\n",
    "            tna += tn\n",
    "                \n",
    "            print(f'{i}/{len(dataloader_val)}', end = '\\r')\n",
    "    print(gt,tpa,fpa,tna,fna)\n",
    "    return gt,tpa,fpa,tna,fna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.56 GiB (GPU 0; 11.78 GiB total capacity; 1.94 GiB already allocated; 841.38 MiB free; 1.97 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-91ffecf1102c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-99d27fe3947c>\u001b[0m in \u001b[0;36mevaluate_classify\u001b[0;34m(val, threshold)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wsod/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, e, aug)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1919\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1921\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   1922\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.56 GiB (GPU 0; 11.78 GiB total capacity; 1.94 GiB already allocated; 841.38 MiB free; 1.97 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "evaluate_classify(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "[982, 75, 76, 5914] [624, 62, 75] [282, 33, 0] [5590] [358, 13, 1]\n",
      "loading annotations into memory...\n",
      "Done (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "[914, 141, 76, 6572] [826, 67, 76] [172, 219, 0] [6189] [88, 74, 0]\n",
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "[820, 94, 76, 7379] [792, 71, 76] [380, 6, 0] [6972] [28, 23, 0]\n",
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "[1101, 77, 75, 7781] [1029, 63, 75] [1359, 40, 0] [6342] [72, 14, 0]\n",
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "[773, 151, 95, 6791] [742, 105, 95] [525, 19, 0] [6247] [31, 46, 0]\n",
      "[[624, 826, 792, 1029, 742], [62, 67, 71, 63, 105], [75, 76, 76, 75, 95]]\n",
      "[[282, 172, 380, 1359, 525], [33, 219, 6, 40, 19], [0, 0, 0, 0, 0]]\n",
      "[[5783, 6617, 7169, 6574, 6512], [6939, 7343, 8269, 8917, 7640], [6971, 7627, 8293, 8959, 7715]]\n",
      "[[358, 88, 28, 72, 31], [13, 74, 23, 14, 46], [1, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "tpa,fpa,tna,fna  = [[],[],[]], [[],[],[]], [[],[],[]], [[],[],[]],\n",
    "for i in range(5):\n",
    "    gt, tp,fp,tn,fn = evaluate_classify(i)\n",
    "    for i in range(3):\n",
    "        tpa[i].append(tp[i])\n",
    "        fpa[i].append(fp[i])\n",
    "        fna[i].append(fn[i])\n",
    "        tna[i].append(sum(gt)-tp[i]-fp[i]-fn[i])\n",
    "print(tpa)\n",
    "print(fpa)\n",
    "print(tna)\n",
    "print(fna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "where(): argument 'input' (position 2) must be Tensor, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6b80dc2e6c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: where(): argument 'input' (position 2) must be Tensor, not float"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0.1,0.5,0.6,0.3]).requires_grad_()\n",
    "c = torch.tensor([1,1,1,1])\n",
    "d = torch.tensor([0,0,0,0])\n",
    "b = torch.where(a>0.5, 1., 0.)\n",
    "loss = (b).sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 1.0000, 1.2000, 0.6000])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zeros_like(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f4edad7bec7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: zeros_like(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "torch.zeros_like(np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,0,0], \n",
    "                        [0,0,0], \n",
    "                        [0,1,1]])\n",
    "\n",
    "b = np.array([[1,0,0],\n",
    "                        [0,0,0],\n",
    "                        [0,1,0]])\n",
    "result = np.all((a-b)==0,axis=1)\n",
    "np.all((1-a)*(1-b), axis = 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.7311, 0.7311]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.from_numpy(a).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b*a\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.5       , 0.5       ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(c.sum(axis = 0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.array([[1,0,9],\n",
    "                        [0,0,0],\n",
    "                        [0,1,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  0, 11])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2]*5).reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1])\n",
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,3,2])\n",
    "b = 0\n",
    "b=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/(a+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import parameters as iap\n",
    "img = np.zeros((256,256))\n",
    "img[100:150, 200:220] = 1\n",
    "seq = iaa.Sequential([\n",
    "                    iaa.Affine(\n",
    "        rotate=iap.DiscreteUniform(-180, 179)*(-1)\n",
    "                    )])\n",
    "ia.seed(10)\n",
    "i = seq(image=img)\n",
    "plt.imshow(i)\n",
    "plt.show()\n",
    "seq = iaa.Sequential([\n",
    "                    iaa.Affine(\n",
    "        rotate=iap.DiscreteUniform(-180, 179)\n",
    "                    )])\n",
    "ia.seed(10)\n",
    "i = seq(image=i)\n",
    "plt.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(name=UnnamedSequential, random_order=False, children=[Affine(name=UnnamedAffine, parameters=[Deterministic(float 1.00000000), (Deterministic(int 0), None, 'px'), Multiply(DiscreteUniform(Deterministic(int -180), Deterministic(int 179)), Deterministic(int -1), False), Deterministic(float 0.00000000), Deterministic(int 1), Deterministic(int 0), Deterministic(constant), auto, False], deterministic=False)], deterministic=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[100:150, 200:220] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0152587890625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1000., dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0153, dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3., 3., ..., 3., 3., 3.],\n",
       "       [3., 3., 3., ..., 3., 3., 3.],\n",
       "       [3., 3., 3., ..., 3., 3., 3.],\n",
       "       ...,\n",
       "       [3., 3., 3., ..., 3., 3., 3.],\n",
       "       [3., 3., 3., ..., 3., 3., 3.],\n",
       "       [3., 3., 3., ..., 3., 3., 3.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = img\n",
    "a += 1\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
