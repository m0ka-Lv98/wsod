{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import bbox_collate\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset\n",
    "from utils import *\n",
    "from torchvision.ops import roi_align\n",
    "from torchvision.ops.boxes import box_iou\n",
    "import copy\n",
    "import numpy as np\n",
    "import cv2\n",
    "from make_dloader import make_data\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open('./config.yaml'))\n",
    "dataset_means = json.load(open(config['dataset']['mean_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = torch.load(f'/data/unagi0/masaoka/val_all1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_val = DataLoader(dataset_val, batch_size=16, shuffle=False, \n",
    "                                num_workers=4, collate_fn=bbox_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.ops import roi_align, nms\n",
    "from utils import calc_iou\n",
    "import torchvision.models as models\n",
    "import yaml\n",
    "from torchvision.ops.boxes import box_iou\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "config = yaml.safe_load(open('./config.yaml'))\n",
    "\n",
    "class focalloss(nn.Module):\n",
    "    def forward(self, classifications, regressions, anchors, annotations):\n",
    "        alpha = 0.25\n",
    "        gamma = 2.0\n",
    "        batch_size = classifications.shape[0]\n",
    "        classification_losses = []\n",
    "        regression_losses = []\n",
    "\n",
    "        anchor = anchors[0, :, :]\n",
    "\n",
    "        anchor_widths  = anchor[:, 2] - anchor[:, 0]\n",
    "        anchor_heights = anchor[:, 3] - anchor[:, 1]\n",
    "        anchor_ctr_x   = anchor[:, 0] + 0.5 * anchor_widths\n",
    "        anchor_ctr_y   = anchor[:, 1] + 0.5 * anchor_heights\n",
    "\n",
    "        for j in range(batch_size):\n",
    "\n",
    "            classification = classifications[j, :, :]\n",
    "            regression = regressions[j, :, :]\n",
    "\n",
    "            bbox_annotation = annotations[j][ :, :]\n",
    "            bbox_annotation = bbox_annotation[bbox_annotation[:, 4] != -1]\n",
    "\n",
    "            if bbox_annotation.shape[0] == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(0).float().cuda())\n",
    "                    classification_losses.append(torch.tensor(0).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(0).float())\n",
    "                    classification_losses.append(torch.tensor(0).float())\n",
    "\n",
    "                continue\n",
    "\n",
    "            classification = torch.clamp(classification, 1e-4, 1.0 - 1e-4)\n",
    "\n",
    "            IoU = calc_iou(anchors[0, :, :], bbox_annotation[:, :4]) # num_anchors x num_annotations\n",
    "\n",
    "            IoU_max, IoU_argmax = torch.max(IoU, dim=1) # num_anchors x 1\n",
    "\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            # compute the loss for classification\n",
    "            targets = torch.ones(classification.shape) * -1\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                targets = targets.cuda()\n",
    "\n",
    "            targets[torch.lt(IoU_max, 0.4), :] = 0\n",
    "\n",
    "            positive_indices = torch.ge(IoU_max, 0.5)\n",
    "\n",
    "            num_positive_anchors = positive_indices.sum()\n",
    "\n",
    "            assigned_annotations = bbox_annotation[IoU_argmax, :]\n",
    "\n",
    "            targets[positive_indices, :] = 0\n",
    "            targets[positive_indices, assigned_annotations[positive_indices, 4].long()] = 1\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                alpha_factor = torch.ones(targets.shape).cuda() * alpha\n",
    "            else:\n",
    "                alpha_factor = torch.ones(targets.shape) * alpha\n",
    "\n",
    "            alpha_factor = torch.where(torch.eq(targets, 1.), alpha_factor, 1. - alpha_factor)\n",
    "            focal_weight = torch.where(torch.eq(targets, 1.), 1. - classification, classification)\n",
    "            focal_weight = alpha_factor * torch.pow(focal_weight, gamma)\n",
    "\n",
    "            bce = -(targets * torch.log(classification) + (1.0 - targets) * torch.log(1.0 - classification))\n",
    "\n",
    "            # cls_loss = focal_weight * torch.pow(bce, gamma)\n",
    "            cls_loss = focal_weight * bce\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, torch.zeros(cls_loss.shape).cuda())\n",
    "            else:\n",
    "                cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, torch.zeros(cls_loss.shape))\n",
    "\n",
    "            classification_losses.append(cls_loss.sum()/torch.clamp(num_positive_anchors.float(), min=1.0))\n",
    "\n",
    "            # compute the loss for regression\n",
    "\n",
    "            if positive_indices.sum() > 0:\n",
    "                assigned_annotations = assigned_annotations[positive_indices, :]\n",
    "\n",
    "                anchor_widths_pi = anchor_widths[positive_indices]\n",
    "                anchor_heights_pi = anchor_heights[positive_indices]\n",
    "                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]\n",
    "                anchor_ctr_y_pi = anchor_ctr_y[positive_indices]\n",
    "\n",
    "                gt_widths  = assigned_annotations[:, 2] - assigned_annotations[:, 0]\n",
    "                gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1]\n",
    "                gt_ctr_x   = assigned_annotations[:, 0] + 0.5 * gt_widths\n",
    "                gt_ctr_y   = assigned_annotations[:, 1] + 0.5 * gt_heights\n",
    "\n",
    "                # clip widths to 1\n",
    "                gt_widths  = torch.clamp(gt_widths, min=1)\n",
    "                gt_heights = torch.clamp(gt_heights, min=1)\n",
    "\n",
    "                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi\n",
    "                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi\n",
    "                targets_dw = torch.log(gt_widths / anchor_widths_pi)\n",
    "                targets_dh = torch.log(gt_heights / anchor_heights_pi)\n",
    "\n",
    "                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh))\n",
    "                targets = targets.t()\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]]).cuda()\n",
    "                else:\n",
    "                    targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
    "\n",
    "                negative_indices = 1 + (~positive_indices)\n",
    "\n",
    "                regression_diff = torch.abs(targets - regression[positive_indices, :])\n",
    "\n",
    "                regression_loss = torch.where(\n",
    "                    torch.le(regression_diff, 1.0 / 9.0),\n",
    "                    0.5 * 9.0 * torch.pow(regression_diff, 2),\n",
    "                    regression_diff - 0.5 / 9.0\n",
    "                )\n",
    "                regression_losses.append(regression_loss.mean().float())\n",
    "            else:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(0).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(0).float())\n",
    "            \n",
    "\n",
    "        return torch.stack(classification_losses).mean(dim=0, keepdim=True), torch.stack(regression_losses).mean(dim=0, keepdim=True)\n",
    "\n",
    "\n",
    "class PyramidFeatures(nn.Module):\n",
    "    def __init__(self, C3_size, C4_size, C5_size, feature_size=256):\n",
    "        super(PyramidFeatures, self).__init__()\n",
    "\n",
    "        # upsample C5 to get P5 from the FPN paper\n",
    "        self.P5_1 = nn.Conv2d(C5_size, feature_size, kernel_size=1, stride=1, padding=0)\n",
    "        self.P5_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.P5_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # add P5 elementwise to C4\n",
    "        self.P4_1 = nn.Conv2d(C4_size, feature_size, kernel_size=1, stride=1, padding=0)\n",
    "        self.P4_upsampled = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.P4_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # add P4 elementwise to C3\n",
    "        self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=1, stride=1, padding=0)\n",
    "        self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # \"P6 is obtained via a 3x3 stride-2 conv on C5\"\n",
    "        self.P6 = nn.Conv2d(C5_size, feature_size, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # \"P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6\"\n",
    "        self.P7_1 = nn.ReLU()\n",
    "        self.P7_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        C3, C4, C5 = inputs\n",
    "\n",
    "        P5_x = self.P5_1(C5)\n",
    "        P5_upsampled_x = self.P5_upsampled(P5_x)\n",
    "        P5_x = self.P5_2(P5_x)\n",
    "\n",
    "        P4_x = self.P4_1(C4)\n",
    "        P4_x = P5_upsampled_x + P4_x\n",
    "        P4_upsampled_x = self.P4_upsampled(P4_x)\n",
    "        P4_x = self.P4_2(P4_x)\n",
    "\n",
    "        P3_x = self.P3_1(C3)\n",
    "        P3_x = P3_x + P4_upsampled_x\n",
    "        P3_x = self.P3_2(P3_x)\n",
    "\n",
    "        P6_x = self.P6(C5)\n",
    "\n",
    "        P7_x = self.P7_1(P6_x)\n",
    "        P7_x = self.P7_2(P7_x)\n",
    "\n",
    "        return [P3_x, P4_x, P5_x, P6_x, P7_x]\n",
    "\n",
    "\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, num_features_in, num_anchors=9, feature_size=256):\n",
    "        super(RegressionModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1)\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.output = nn.Conv2d(feature_size, num_anchors * 4, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.act1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.act2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.act3(out)\n",
    "\n",
    "        out = self.conv4(out)\n",
    "        out = self.act4(out)\n",
    "\n",
    "        out = self.output(out)\n",
    "\n",
    "        # out is B x C x W x H, with C = 4*num_anchors\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "\n",
    "        return out.contiguous().view(out.shape[0], -1, 4)\n",
    "    \n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, num_features_in, num_anchors=9, num_classes=80, prior=0.01, feature_size=256):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors = num_anchors\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=3, padding=1)\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.output = nn.Conv2d(feature_size, num_anchors * num_classes, kernel_size=3, padding=1)\n",
    "        self.output_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.act1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.act2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.act3(out)\n",
    "\n",
    "        out = self.conv4(out)\n",
    "        out = self.act4(out)\n",
    "\n",
    "        out = self.output(out)\n",
    "        out = self.output_act(out)\n",
    "\n",
    "        # out is B x C x W x H, with C = n_classes + n_anchors\n",
    "        out1 = out.permute(0, 2, 3, 1)\n",
    "\n",
    "        batch_size, width, height, channels = out1.shape\n",
    "\n",
    "        out2 = out1.view(batch_size, width, height, self.num_anchors, self.num_classes)\n",
    "\n",
    "        return out2.contiguous().view(x.shape[0], -1, self.num_classes)\n",
    "    \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        y = target #bs*proposal,4\n",
    "        \n",
    "        logit = F.softmax(input,dim=-1) #bs*proposal,4\n",
    "        logit = logit.clamp(self.eps, 1. - self.eps)\n",
    "        loss = -1 * y * torch.log(logit) # cross entropy\n",
    "        loss = loss * ((1 - logit) ** self.gamma) # focal loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def  __init__(self,size_list=[]):\n",
    "        super().__init__()\n",
    "        assert len(size_list)>0\n",
    "        self.avgpool_list = []\n",
    "        for size in size_list:\n",
    "            self.avgpool_list.append(nn.Sequential(nn.AdaptiveAvgPool2d(size),\n",
    "                                                    nn.Flatten()))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        vec = []\n",
    "        for avgpool in self.avgpool_list:\n",
    "            vec.append(avgpool(x))\n",
    "        vec = torch.cat(vec,1)\n",
    "        return vec\n",
    "\n",
    "class _ROIPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, inputs, rois):\n",
    "        #rois: bs,2000,4 \n",
    "        #output: bs, 2000, ch, h, w\n",
    "        rois = [r for r in rois]\n",
    "        h, w = inputs.shape[2], inputs.shape[3]\n",
    "        res = roi_align(inputs, rois, 7, spatial_scale=w/512)\n",
    "        return res\n",
    "\n",
    "class vector_extractor(nn.Module):\n",
    "    \"\"\"input: images, proposals\n",
    "         output: feature vector\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        layers = list(model.children())[:-2]\n",
    "        self.feature_map = nn.Sequential(*layers)\n",
    "        self.roi_pool = _ROIPool()\n",
    "        #self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feature_vector = nn.Sequential(ASPP([1,2]),\n",
    "                                            #nn.AdaptiveAvgPool2d(1),\n",
    "                                            nn.Flatten(),\n",
    "                                            nn.Linear(512*(5), 2048),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.BatchNorm1d(2048),\n",
    "                                            nn.Linear(2048, 512),\n",
    "                                            nn.BatchNorm1d(512),\n",
    "                                            nn.ReLU(inplace=True))\n",
    "    def forward(self, inputs, rois):\n",
    "        f = self.feature_map(inputs)\n",
    "        f = self.roi_pool(f, rois)\n",
    "        #f = self.gap(f).view(f.shape[0], f.shape[1]) #batch*proposal, ch\n",
    "        f = self.feature_vector(f) \n",
    "        return f\n",
    "class vector_extractor_pyramid(nn.Module):\n",
    "    \"\"\"input: images, proposals\n",
    "         output: feature vector\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        self.base = nn.Sequential(*list(model.children())[:4])\n",
    "        self.layer1 = list(model.children())[4]\n",
    "        self.layer2 = list(model.children())[5]\n",
    "        self.layer3 = list(model.children())[6]\n",
    "        self.layer4 = list(model.children())[7]\n",
    "        self.roi_pool = _ROIPool()\n",
    "        #self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feature_vector = nn.Sequential(ASPP([1,2]),\n",
    "                                            #nn.AdaptiveAvgPool2d(1),\n",
    "                                            nn.Flatten(),\n",
    "                                            nn.Linear(512*(5), 2048),\n",
    "                                            nn.ReLU(inplace=True),\n",
    "                                            nn.BatchNorm1d(2048),\n",
    "                                            nn.Linear(2048, 512),\n",
    "                                            nn.BatchNorm1d(512),\n",
    "                                            nn.ReLU(inplace=True))\n",
    "    def forward(self, inputs, rois):\n",
    "        x = self.base(inputs)\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "        f = self.roi_pool(x4, rois)\n",
    "        #f = self.gap(f).view(f.shape[0], f.shape[1]) #batch*proposal, ch\n",
    "        f = self.feature_vector(f) \n",
    "        return f,x2,x3,x4\n",
    "    \n",
    "class MIDN(nn.Module):\n",
    "    \"\"\"input: feature vector, labels\n",
    "         output: scores per proposal, loss\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_in = 512\n",
    "        self.layer_c = nn.Linear(c_in, 4)\n",
    "        self.layer_d = nn.Linear(c_in, 4)\n",
    "        self.softmax_c = nn.Softmax(dim=2)\n",
    "        self.softmax_d = nn.Softmax(dim=1)\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.upper = 1-1e-8\n",
    "        self.lower = 1e-8\n",
    "    def forward(self, inputs, labels, num):\n",
    "        bs, proposal = inputs.shape[0]//num, num\n",
    "        x_c = self.layer_c(inputs).view(bs, proposal, -1) #bs, proposal, 4\n",
    "        x_d = self.layer_d(inputs).view(bs, proposal, -1)\n",
    "        sigma_c = self.softmax_c(x_c)\n",
    "        sigma_d = self.softmax_d(x_d)\n",
    "        x_r = sigma_c * sigma_d #bs, proposal, 4\n",
    "        phi_c = x_r.sum(dim=1) #bs, 4\n",
    "        phi_c = torch.clamp(phi_c, self.lower,self.upper)\n",
    "        scaled = x_r/(torch.max(x_r,1)[0].unsqueeze(1)+1e-8)*phi_c.unsqueeze(1)\n",
    "        loss = self.loss(phi_c, labels)\n",
    "        print(loss)\n",
    "        if not self.training:\n",
    "            #print(f'scaled = {scaled.data.cpu().numpy()}')\n",
    "            return x_r#scaled#\n",
    "        return  scaled, loss#x_r,loss#phi_c.unsqueeze(1), loss #sigma_c,loss#\n",
    "        \n",
    "\n",
    "class ICR(nn.Module):\n",
    "    \"\"\"input: feature vector (bs*proposal, ch)\n",
    "                     k-1th proposal scores(bs, proposal,3or4)\n",
    "                     supervision (label) (bs)\n",
    "                     ROI proposals\n",
    "         output: refined proposal scores, loss\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_in = 512\n",
    "        self.I_t = 0.1\n",
    "        self.fc = nn.Linear(c_in, 4)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.fl = FocalLoss(gamma=2)\n",
    "        self.one = nn.Parameter(torch.tensor([1.])).requires_grad_(False)\n",
    "        self.zero = nn.Parameter(torch.tensor([0.])).requires_grad_(False)\n",
    "        self.d = self.zero.device\n",
    "        \n",
    "    def forward(self, inputs, pre_score, labels, rois, num):\n",
    "        bs, proposal = inputs.shape[0]//num, num\n",
    "        pre_score = pre_score.clone().detach()\n",
    "        xr_k = self.fc(inputs).view(bs, proposal, -1) #bs, proposal, 4\n",
    "        logit = self.softmax(xr_k)\n",
    "        _xr_k = xr_k.view(bs*proposal, -1)\n",
    "        y_k = torch.zeros(bs, proposal, 4).cuda()\n",
    "        y_k[:, :, 3] = 1\n",
    "        \n",
    "        w = torch.stack([torch.cat([self.zero]*proposal)]*bs,0)\n",
    "        I = torch.stack([torch.cat([self.zero]*proposal)]*bs,0)\n",
    "        for batch in range(bs):\n",
    "            for c in range(4):\n",
    "                if labels[batch][c]:\n",
    "                    label = c\n",
    "                    j_list = (pre_score[batch,:,c]>0.5).nonzero().squeeze()\n",
    "                    x_list = pre_score[batch,j_list,c]\n",
    "                    if (j_list).size() == torch.Size([0]) or (j_list).size() == torch.Size([1]) or (j_list).size() == torch.Size([]):\n",
    "                        m = torch.max(pre_score[batch, :, c], 0)\n",
    "                        x = m[0].item()\n",
    "                        j = m[1].item()\n",
    "                        x_list = [x]\n",
    "                        j_list =[j]\n",
    "                    mat = box_iou(rois[batch], rois[batch][j_list])\n",
    "                    for i,j in enumerate(j_list):\n",
    "                        _I = mat[:,i]\n",
    "                        old = I[batch].clone()\n",
    "                        I[batch] = torch.where(_I > old,_I,old)\n",
    "                        pre = w[batch].clone()\n",
    "                        w[batch] = torch.where(_I > old,self.one*x_list[i],pre)\n",
    "                        p = y_k[batch, :, 3].clone()\n",
    "                        y_k[batch, :, 3] = torch.where(_I > self.I_t,self.zero,p)\n",
    "                        q = y_k[batch, :, c].clone()\n",
    "                        y_k[batch, :, c] = torch.where(_I > self.I_t,self.one,q)\n",
    "                        \n",
    "                \n",
    "        y_k = y_k.view(bs*proposal, -1)\n",
    "        w = w.view(bs*proposal, 1)\n",
    "        \n",
    "        imbalance_list = y_k.float().sum(dim=0)\n",
    "        bg_num = (w!=0.).sum()-imbalance_list[:-1].sum()\n",
    "        imbalance_list[-1] = bg_num\n",
    "        loss = self.fl(_xr_k.float(), y_k)\n",
    "        loss = (w*loss)/(imbalance_list+1e-7)#bs*proposal,4\n",
    "        loss = loss.view(bs,proposal,-1)\n",
    "        w_ = torch.exp(logit)#bs,proposal,4\n",
    "        lab = labels.unsqueeze(1)#bs,1,4\n",
    "        \n",
    "        mask = 1-lab\n",
    "        w_ = w_*mask+lab\n",
    "        loss = loss*w_\n",
    "        loss = loss.sum()/bs\n",
    "        print(loss)\n",
    "        if not self.training:\n",
    "            return logit\n",
    "        return logit, loss\n",
    "\n",
    "class OICR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.v_extractor = vector_extractor()\n",
    "        self.midn = MIDN()\n",
    "        self.icr1 = ICR()\n",
    "        self.icr2 = ICR()\n",
    "        self.icr3 = ICR()\n",
    "        \n",
    "    def forward(self, inputs, labels, rois, num):\n",
    "        if self.training:\n",
    "            labels = labels.squeeze()\n",
    "            rois = rois.squeeze()\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            x, midn_loss = self.midn(v, labels, num)\n",
    "            x, loss1 = self.icr1(v, x, labels, rois, num)\n",
    "            x, loss2 = self.icr2(v, x, labels, rois, num)\n",
    "            x, loss3 = self.icr3(v, x, labels, rois, num) \n",
    "            loss = midn_loss + (loss1 + loss2 + loss3)\n",
    "            return x, loss.unsqueeze(0),midn_loss.unsqueeze(0),loss1.unsqueeze(0),loss2.unsqueeze(0),loss3.unsqueeze(0)\n",
    "        else:\n",
    "            self.three = torch.tensor([3.]).cuda()\n",
    "            self.inf = torch.tensor([-1.]).cuda()\n",
    "            #rois = rois.squeeze()\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            x = self.midn(v, labels, num)\n",
    "            print('---------------------------------------------------')\n",
    "            print('icr1')\n",
    "            x = self.icr1(v, x, labels, rois, num) \n",
    "            print('---------------------------------------------------')\n",
    "            print('icr2')\n",
    "            x = self.icr2(v, x, labels, rois, num) \n",
    "            print('---------------------------------------------------')\n",
    "            print('icr3')\n",
    "            x = self.icr3(v, x, labels, rois, num) \n",
    "            x, rois = x[0], rois[0].cuda()\n",
    "            rois = rois[torch.max(x,1)[1]!=3]\n",
    "            x = x[torch.max(x,1)[1]!=3]\n",
    "            print(f'x={x}')\n",
    "            if x.size() == torch.Size([0,4]):\n",
    "                return torch.tensor([]),torch.tensor([]),torch.tensor([])\n",
    "            #label = torch.max(labels,1)[1]\n",
    "            #score = x[:,label].squeeze()\n",
    "            #index = nms(rois,score,0.5)\n",
    "            #scores = score[index]\n",
    "           # bboxes = rois[index]\n",
    "            #labels = torch.cat([label]*(len(index)))\n",
    "            classes = torch.max(x,1)[1] #proposals\n",
    "            scores = torch.max(x,1)[0] #proposals\n",
    "            print(rois.shape,scores.shape,classes.shape)\n",
    "            index = nms(rois,scores,0.5)\n",
    "            scores = scores[index]\n",
    "            labels = classes[index]\n",
    "            bboxes = rois[index]\n",
    "            return scores, labels, bboxes\n",
    "\n",
    "def generate_gt(scores_list,rois_list,labels):\n",
    "    #scores:bs,proposal,4; rois_list:bs,n,4; labels:bs,4\n",
    "    gt_list = []\n",
    "    bs,proposal,_ = scores_list.shape\n",
    "    for batch in range(bs):\n",
    "        label = torch.max(labels[batch],0)[1]\n",
    "        if label == 3:\n",
    "            gt_list.append(torch.tensor([]))\n",
    "            continue\n",
    "        rois = rois_list[batch]\n",
    "        scores = scores_list[batch]\n",
    "        rois = rois[torch.max(scores,1)[1]!=3]\n",
    "        scores = scores[torch.max(scores,1)[1]!=3]\n",
    "        scores = scores[:,label]\n",
    "        if len(scores)==0:\n",
    "            gt_list.append(torch.tensor([]))\n",
    "            continue\n",
    "        index = nms(rois,scores,0.5)\n",
    "        rois = rois[index]\n",
    "        scores = scores[index]\n",
    "        for i in range(len(scores)):\n",
    "            if scores[i]>0.5:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        rois = rois[:i]\n",
    "        scores = scores[:i]\n",
    "        gt_list.append(rois)\n",
    "    return gt_list\n",
    "\n",
    "class Detection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cls = nn.Linear(512,4)\n",
    "        self.reg = nn.Linear(512,4)\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "        self.l1 = nn.SmoothL1Loss(reduction='none')\n",
    "        self.zero = nn.Parameter(torch.tensor(0.)).requires_grad_(False)\n",
    "    def forward(self,v,gt_list,rois_list,labels,pre_score):\n",
    "        if not self.training:\n",
    "            cls = F.softmax(self.cls(v),dim=-1)#proposal,4\n",
    "            reg = self.reg(v)#proposal,4\n",
    "            tx,ty,tw,th = reg[:,0],reg[:,1],reg[:,2],reg[:,3]\n",
    "            r = rois_list[0]\n",
    "            rx = (r[:,2]+r[:,0])/2\n",
    "            ry = (r[:,3]+r[:,1])/2\n",
    "            rw = (r[:,2]-r[:,0])/2\n",
    "            rh = (r[:,3]-r[:,1])/2\n",
    "            gx = tx*rw+rx\n",
    "            gy = ty*rh+ry\n",
    "            gw = rw*torch.exp(tw)\n",
    "            gh = rh*torch.exp(th)\n",
    "            x0 = gx-gw/2\n",
    "            x1 = gx+gw/2\n",
    "            y0 = gy-gh/2\n",
    "            y1 = gy+gh/2\n",
    "            boxes = torch.stack([x0,y0,x1,y1],1)\n",
    "            return boxes, cls\n",
    "        bs = len(gt_list)\n",
    "        pre_score = pre_score.clone().detach()\n",
    "        classify = self.cls(v).view(bs,-1,4) #bs,proposal,4\n",
    "        proposal = classify.shape[1]\n",
    "        reg = self.reg(v).view(bs,-1,4)\n",
    "        \n",
    "        c_list = self.zero.clone()\n",
    "        l1_list= self.zero.clone()\n",
    "        i = 0\n",
    "        for batch in range(bs):\n",
    "            label = torch.max(labels[batch],0)[1]\n",
    "            if gt_list[batch].size()==torch.Size([0,4]) or gt_list[batch].size()==torch.Size([0]) :\n",
    "                target = torch.stack([label]*proposal,0)\n",
    "                c_loss = self.ce(classify[batch],target).mean()\n",
    "                c_list += c_loss\n",
    "                continue\n",
    "            gt_list[batch] = gt_list[batch].float()\n",
    "            i+=1\n",
    "            target = torch.stack([label]*proposal,0)\n",
    "            c_loss = self.ce(classify[batch],target)*pre_score[batch,:,label] #proposal,4\n",
    "            ious = box_iou(gt_list[batch],rois_list[batch])\n",
    "            _ious = ious>0.5\n",
    "            mask = _ious.any(dim=0)\n",
    "            c_loss = (c_loss*mask).sum()/(mask.sum()+1e-7)\n",
    "            index = torch.max(ious,0)[1]\n",
    "            g = gt_list[batch][index]\n",
    "            gx = (g[:,2]+g[:,0])/2\n",
    "            gy = (g[:,3]+g[:,1])/2\n",
    "            gw = (g[:,2]-g[:,0])/2\n",
    "            gh = (g[:,3]-g[:,1])/2\n",
    "            r = rois_list[batch]\n",
    "            rx = (r[:,2]+r[:,0])/2\n",
    "            ry = (r[:,3]+r[:,1])/2\n",
    "            rw = (r[:,2]-r[:,0])/2\n",
    "            rh = (r[:,3]-r[:,1])/2\n",
    "            tx = (gx-rx)/(rw+1e-8)\n",
    "            ty = (gy-ry)/(rh+1e-8)\n",
    "            tw = torch.log(gw/(rw+1e-8))\n",
    "            th = torch.log(gh/(rh+1e-8))\n",
    "            t = torch.stack([tx,ty,tw,th],1)\n",
    "            l1_loss = (self.l1(reg[batch],t).sum(dim=1)*mask*pre_score[batch,:,label]).sum()/(bs*proposal)#mask.sum()\n",
    "            c_list+=c_loss\n",
    "            l1_list+=l1_loss\n",
    "        if i == 0:\n",
    "            return c_list+l1_list\n",
    "        else:\n",
    "            return c_list/bs+l1_list/i\n",
    "                \n",
    "                \n",
    "class OICRe2e(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.v_extractor = vector_extractor()\n",
    "        self.midn = MIDN()\n",
    "        self.icr1 = ICR()\n",
    "        self.icr2 = ICR()\n",
    "        self.icr3 = ICR()\n",
    "        self.detection = Detection()\n",
    "        \n",
    "    def forward(self, inputs, labels, rois, num):\n",
    "        if self.training:\n",
    "            labels = labels.squeeze()\n",
    "            rois = rois.squeeze()\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            x, midn_loss = self.midn(v, labels, num)\n",
    "            x, loss1 = self.icr1(v, x, labels, rois, num)\n",
    "            x, loss2 = self.icr2(v, x, labels, rois, num)\n",
    "            x, loss3 = self.icr3(v, x, labels, rois, num) \n",
    "            gt_list = generate_gt(x,rois,labels) #n x 4がbs個 gt_list[0]: n,4            \n",
    "            loss_detection = self.detection(v,gt_list,rois,labels,x)\n",
    "            loss = midn_loss + (loss1 + loss2 + loss3)+loss_detection\n",
    "            return x, loss.unsqueeze(0),midn_loss.unsqueeze(0),loss1.unsqueeze(0),loss2.unsqueeze(0),loss3.unsqueeze(0),loss_detection.unsqueeze(0)\n",
    "        else:\n",
    "            self.three = torch.tensor([3.]).cuda()\n",
    "            self.inf = torch.tensor([-1.]).cuda()\n",
    "            #rois = rois.squeeze()\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            rois,x = self.detection(v,None,rois,None,None)\n",
    "            '''x = self.midn(v, labels, num)\n",
    "            print('---------------------------------------------------')\n",
    "            print('icr1')\n",
    "            x = self.icr1(v, x, labels, rois, num) \n",
    "            print('---------------------------------------------------')\n",
    "            print('icr2')\n",
    "            x = self.icr2(v, x, labels, rois, num) \n",
    "            print('---------------------------------------------------')\n",
    "            print('icr3')\n",
    "            x = self.icr3(v, x, labels, rois, num) \n",
    "            x, rois = x[0], rois[0].cuda()\n",
    "            rois = rois[torch.max(x,1)[1]!=3]\n",
    "            x = x[torch.max(x,1)[1]!=3]\n",
    "            print(f'x={x}')'''\n",
    "            \n",
    "            rois = rois[torch.max(x,1)[1]!=3]\n",
    "            x = x[torch.max(x,1)[1]!=3]\n",
    "            print(f'x={x}')\n",
    "            if x.size() == torch.Size([0,4]):\n",
    "                return torch.tensor([]),torch.tensor([]),torch.tensor([])\n",
    "            classes = torch.max(x,1)[1] #proposals\n",
    "            scores = torch.max(x,1)[0] #proposals\n",
    "            print(rois.shape,scores.shape,classes.shape)\n",
    "            index = nms(rois,scores,0.5)\n",
    "            scores = scores[index]\n",
    "            labels = classes[index]\n",
    "            bboxes = rois[index]\n",
    "            return scores, labels, bboxes\n",
    "\n",
    "\n",
    "class SAV(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.v_extractor = vector_extractor()\n",
    "        self.midn = MIDN()\n",
    "        self.icr1 = ICR()\n",
    "        self.icr2 = ICR()\n",
    "        self.icr3 = ICR()\n",
    "        self.detection = Detection()\n",
    "        self.mat = nn.Parameter(torch.zeros((512,512))).requires_grad_(False)\n",
    "        self.zero = nn.Parameter(torch.tensor([0.])).requires_grad_(False)\n",
    "        \n",
    "    def forward(self, inputs, labels, rois, num):\n",
    "        if self.training:\n",
    "            labels = labels.squeeze()\n",
    "            rois = rois.squeeze()\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            x, midn_loss = self.midn(v, labels, num)\n",
    "            x1, loss1 = self.icr1(v, x, labels, rois, num)\n",
    "            x2, loss2 = self.icr2(v, x1, labels, rois, num)\n",
    "            x3, loss3 = self.icr3(v, x2, labels, rois, num) \n",
    "            #return x1,x2,x3,labels,rois\n",
    "            gt_list = self.generate_gt_sav(x1,x2,x3,rois,labels) #n x 4がbs個 gt_list[0]: n,4            \n",
    "            loss_detection = self.detection(v,gt_list,rois,labels,x)\n",
    "            loss = midn_loss + (loss1 + loss2 + loss3)+loss_detection\n",
    "            return x, loss.unsqueeze(0),midn_loss.unsqueeze(0),loss1.unsqueeze(0),loss2.unsqueeze(0),loss3.unsqueeze(0),loss_detection.unsqueeze(0)\n",
    "        else:\n",
    "            self.three = torch.tensor([3.]).cuda()\n",
    "            self.inf = torch.tensor([-1.]).cuda()\n",
    "            #rois = rois.squeeze()\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            rois,x = self.detection(v,None,rois,None,None)\n",
    "            rois = rois[torch.max(x,1)[1]!=3]\n",
    "            x = x[torch.max(x,1)[1]!=3]\n",
    "            print(f'x={x}')\n",
    "            if x.size() == torch.Size([0,4]):\n",
    "                return torch.tensor([]),torch.tensor([]),torch.tensor([])\n",
    "            classes = torch.max(x,1)[1] #proposals\n",
    "            scores = torch.max(x,1)[0] #proposals\n",
    "            print(rois.shape,scores.shape,classes.shape)\n",
    "            index = nms(rois,scores,0.5)\n",
    "            scores = scores[index]\n",
    "            labels = classes[index]\n",
    "            bboxes = rois[index]\n",
    "            return scores, labels, bboxes\n",
    "\n",
    "    def generate_gt_sav(self,x1,x2,x3,rois_list,labels_list):\n",
    "        bs,proposal,_ = x1.shape\n",
    "        gt_list = []\n",
    "        for batch in range(bs):\n",
    "            mat = self.mat.clone()\n",
    "            label = torch.max(labels_list[batch],0)[1]\n",
    "            if label == 3:\n",
    "                gt_list.append(torch.tensor([]))\n",
    "                continue\n",
    "            rois = rois_list[batch]\n",
    "            score_list = []\n",
    "            \n",
    "            for score in [x1[batch],x2[batch],x3[batch]]:\n",
    "                score_list.append(score[:,label])\n",
    "            score = (score_list[0]+score_list[1]+score_list[2])/3\n",
    "            index = nms(rois,score,0.5)\n",
    "            rois = rois[index]\n",
    "            score = score[index]\n",
    "            for r in range(len(rois)):\n",
    "                mat[int(rois[r,1]):int(rois[r,3]),int(rois[r,0]):int(rois[r,2])] += score[r]\n",
    "            mat = mat/(mat.max()+1e-8)\n",
    "            mat = torch.where(mat>0.5,mat,self.zero).cpu().detach().numpy()\n",
    "            heatmap = np.uint8(255*mat)\n",
    "            LAB = cv2.connectedComponentsWithStats(heatmap)\n",
    "            n = LAB[0] - 1\n",
    "            data = np.delete(LAB[2], 0, 0)\n",
    "            boxes = torch.tensor([])\n",
    "            for i in range(n):\n",
    "                X0 = data[i][0]\n",
    "                Y0 = data[i][1]\n",
    "                X1 = data[i][0] + data[i][2]\n",
    "                Y1 = data[i][1] + data[i][3]\n",
    "                if boxes.shape[0] == 0:\n",
    "                    boxes = torch.tensor([[X0,Y0,X1,Y1]]).cuda()\n",
    "                else:\n",
    "                    boxes = torch.cat((boxes, torch.tensor([[X0,Y0,X1,Y1]]).cuda()), dim=0)\n",
    "            gt_list.append(boxes)\n",
    "        return gt_list\n",
    "    \n",
    "class SAV_Retina(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.v_extractor = vector_extractor_pyramid()\n",
    "        self.midn = MIDN()\n",
    "        self.icr1 = ICR()\n",
    "        self.icr2 = ICR()\n",
    "        self.icr3 = ICR()\n",
    "        num_classes = 3\n",
    "        self.detection = Detection()\n",
    "        self.mat = nn.Parameter(torch.zeros((512,512))).requires_grad_(False)\n",
    "        self.zero = nn.Parameter(torch.tensor([0.])).requires_grad_(False)\n",
    "        self.fpn = PyramidFeatures(128, 256, 512)\n",
    "        self.regressionModel = RegressionModel(256)\n",
    "        self.classificationModel = ClassificationModel(256, num_classes=num_classes)\n",
    "        self.anchors = Anchors()\n",
    "\n",
    "        self.regressBoxes = BBoxTransform()\n",
    "\n",
    "        self.clipBoxes = ClipBoxes()\n",
    "\n",
    "        self.focalLoss = focalloss()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        prior = 0.01\n",
    "\n",
    "        self.classificationModel.output.weight.data.fill_(0)\n",
    "        self.classificationModel.output.bias.data.fill_(-math.log((1.0 - prior) / prior))\n",
    "\n",
    "        self.regressionModel.output.weight.data.fill_(0)\n",
    "        self.regressionModel.output.bias.data.fill_(0)\n",
    "        \n",
    "    def forward(self, inputs, labels, rois, num):\n",
    "        if self.training:\n",
    "            labels = labels.squeeze()\n",
    "            rois = rois.squeeze()\n",
    "            v,f2,f3,f4 = self.v_extractor(inputs, rois)\n",
    "            x, midn_loss = self.midn(v, labels, num)\n",
    "            x1, loss1 = self.icr1(v, x, labels, rois, num)\n",
    "            x2, loss2 = self.icr2(v, x1, labels, rois, num)\n",
    "            x3, loss3 = self.icr3(v, x2, labels, rois, num) \n",
    "            #return x1,x2,x3,labels,rois\n",
    "            gt_list = self.generate_gt_sav(x1,x2,x3,rois,labels) #n x 4がbs個 gt_list[0]: n,4 \n",
    "            #return gt_list\n",
    "            features = self.fpn([f2, f3, f4])\n",
    "\n",
    "            regression = torch.cat([self.regressionModel(feature) for feature in features], dim=1)\n",
    "\n",
    "            classification = torch.cat([self.classificationModel(feature) for feature in features], dim=1)\n",
    "\n",
    "            anchors = self.anchors(inputs)\n",
    "            c_loss,r_loss = self.focalLoss(classification, regression, anchors, gt_list)\n",
    "            c_loss = c_loss.mean()\n",
    "            r_loss = r_loss.mean()\n",
    "            loss = midn_loss + (loss1 + loss2 + loss3)+c_loss+r_loss\n",
    "            return x, loss.unsqueeze(0),midn_loss.unsqueeze(0),loss1.unsqueeze(0),loss2.unsqueeze(0),loss3.unsqueeze(0),(c_loss+r_loss).unsqueeze(0)\n",
    "        else:\n",
    "            v,f2,f3,f4 = self.v_extractor(inputs, rois)\n",
    "            features = self.fpn([f2, f3, f4])\n",
    "\n",
    "            regression = torch.cat([self.regressionModel(feature) for feature in features], dim=1)\n",
    "\n",
    "            classification = torch.cat([self.classificationModel(feature) for feature in features], dim=1)\n",
    "\n",
    "            anchors = self.anchors(inputs)\n",
    "            transformed_anchors = self.regressBoxes(anchors, regression)\n",
    "            transformed_anchors = self.clipBoxes(transformed_anchors, inputs)\n",
    "\n",
    "            scores = torch.max(classification, dim=2, keepdim=True)[0]\n",
    "\n",
    "            scores_over_thresh = (scores > 0.05)[0, :, 0]\n",
    "\n",
    "            if scores_over_thresh.sum() == 0:\n",
    "                # no boxes to NMS, just return\n",
    "                return [torch.zeros(0), torch.zeros(0), torch.zeros(0, 4)]\n",
    "\n",
    "            classification = classification[:, scores_over_thresh, :]\n",
    "            transformed_anchors = transformed_anchors[:, scores_over_thresh, :]\n",
    "            scores = scores[:, scores_over_thresh, :]\n",
    "\n",
    "            anchors_nms_idx = nms(transformed_anchors[0,:,:], scores[0,:,0], 0.5)\n",
    "\n",
    "            nms_scores, nms_class = classification[0, anchors_nms_idx, :].max(dim=1)\n",
    "\n",
    "            return [nms_scores, nms_class, transformed_anchors[0, anchors_nms_idx, :]]\n",
    "        \n",
    "\n",
    "    def generate_gt_sav(self,x1,x2,x3,rois_list,labels_list):\n",
    "        bs,proposal,_ = x1.shape\n",
    "        gt_list = []\n",
    "        for batch in range(bs):\n",
    "            mat = self.mat.clone()\n",
    "            label = torch.max(labels_list[batch],0)[1]\n",
    "            if label == 3:\n",
    "                gt_list.append(torch.empty(0,5))\n",
    "                continue\n",
    "            rois = rois_list[batch]\n",
    "            score_list = []\n",
    "            \n",
    "            for score in [x1[batch],x2[batch],x3[batch]]:\n",
    "                score_list.append(score[:,label])\n",
    "            score = (score_list[0]+score_list[1]+score_list[2])/3\n",
    "            index = nms(rois,score,0.5)\n",
    "            rois = rois[index]\n",
    "            score = score[index]\n",
    "            for r in range(len(rois)):\n",
    "                mat[int(rois[r,1]):int(rois[r,3]),int(rois[r,0]):int(rois[r,2])] += score[r]\n",
    "            mat = mat/(mat.max()+1e-8)\n",
    "            mat = torch.where(mat>0.5,mat,self.zero).cpu().detach().numpy()\n",
    "            heatmap = np.uint8(255*mat)\n",
    "            LAB = cv2.connectedComponentsWithStats(heatmap)\n",
    "            n = LAB[0] - 1\n",
    "            data = np.delete(LAB[2], 0, 0)\n",
    "            boxes = torch.empty(0,5)\n",
    "            for i in range(n):\n",
    "                X0 = data[i][0]\n",
    "                Y0 = data[i][1]\n",
    "                X1 = data[i][0] + data[i][2]\n",
    "                Y1 = data[i][1] + data[i][3]\n",
    "                if boxes.shape[0] == 0:\n",
    "                    boxes = torch.tensor([[X0,Y0,X1,Y1,label]]).cuda()\n",
    "                else:\n",
    "                    boxes = torch.cat((boxes, torch.tensor([[X0,Y0,X1,Y1,label]]).cuda()), dim=0)\n",
    "            gt_list.append(boxes)\n",
    "        return gt_list\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "oicr = SAV_Retina()\n",
    "#oicr.load_state_dict(torch.load(\"/data/unagi0/masaoka/wsod/model/oicr/OICRe2eflx0.0001_1.pt\"))\n",
    "oicr.cuda()\n",
    "opt = torch.optim.Adam(oicr.parameters(), lr = 1e-5, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proposal = 1452\n",
      "tensor(0.5547, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.0333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "losses = tensor([0.8485], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.5547], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.0333], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.0787], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.0475], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.1343], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
      "tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "proposal = 1413\n",
      "tensor(0.5491, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.0748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "losses = tensor([1.1673], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.5491], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.0499], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.0795], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.0748], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.4140], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
      "tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "proposal = 1327\n",
      "tensor(0.5483, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.0128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.0262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "losses = tensor([0.6138], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.5483], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.0128], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.0266], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.0262], device='cuda:0', grad_fn=<UnsqueezeBackward0>),tensor([0.], device='cuda:0')\n",
      "tensor(0.6138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "proposal = 1381\n",
      "tensor(0.5436, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e09cc282bd7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#g = oicr(data[\"img\"].cuda().float(), labels, rois, n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moicr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'losses = {loss},{m},{l1},{l2},{l3},{ld}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2019.10/envs/cuda9/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-edc6b9de8b95>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels, rois, num)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0micr3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0;31m#return x1,x2,x3,labels,rois\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mgt_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_gt_sav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#n x 4がbs個 gt_list[0]: n,4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0;31m#return gt_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-edc6b9de8b95>\u001b[0m in \u001b[0;36mgenerate_gt_sav\u001b[0;34m(self, x1, x2, x3, rois_list, labels_list)\u001b[0m\n\u001b[1;32m    921\u001b[0m                     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m                     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0mgt_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgt_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader_val):\n",
    "    opt.zero_grad()\n",
    "    labels, n, t, v, u= data2target(data)\n",
    "    labels = labels.unsqueeze(1).unsqueeze(2).cuda().float() # bs, 1, 1, num_class\n",
    "    rois = [r.cuda().float() for r in data[\"p_bboxes\"]]\n",
    "    n = min(list(map(lambda x: x.shape[0], rois)))\n",
    "    n = min(n,2000)\n",
    "    print(f'proposal = {n}')\n",
    "    for ind, tensor in enumerate(rois):\n",
    "        rois[ind] = rois[ind][:n,:]\n",
    "    rois = torch.stack(rois, dim=0) \n",
    "    rois = rois.unsqueeze(1) #bs, 1, n, 4\n",
    "    #g = oicr(data[\"img\"].cuda().float(), labels, rois, n)\n",
    "    #break\n",
    "    output, loss,m,l1,l2,l3,ld = oicr(data[\"img\"].cuda().float(), labels, rois, n)\n",
    "    print(f'losses = {loss},{m},{l1},{l2},{l3},{ld}')\n",
    "    loss = m+l1+l2+l3+ld*i/len(dataloader_val) \n",
    "    loss = loss.mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss)\n",
    "    print(f'{i}/{len(dataloader_val)}, {loss}', end='\\r')\n",
    "    print('------------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[403,  43, 407,  71],\n",
       "        [  6,  48, 478, 501],\n",
       "        [347,  49, 348,  54],\n",
       "        [202,  52, 203,  59],\n",
       "        [331,  64, 332,  65],\n",
       "        [339,  64, 340,  65],\n",
       "        [347,  64, 353,  66],\n",
       "        [ 61,  77,  72,  81],\n",
       "        [160,  78, 162,  85],\n",
       "        [347,  78, 357,  98],\n",
       "        [270,  80, 272,  81],\n",
       "        [339,  80, 340,  81],\n",
       "        [331,  87, 332,  90],\n",
       "        [338,  87, 340,  90],\n",
       "        [160,  91, 162,  92],\n",
       "        [102,  97, 120,  98],\n",
       "        [338,  96, 340,  98],\n",
       "        [347,  99, 353, 102],\n",
       "        [455, 100, 467, 102],\n",
       "        [330, 105, 332, 108],\n",
       "        [337, 105, 340, 108],\n",
       "        [347, 105, 353, 108],\n",
       "        [ 13, 111,  22, 119],\n",
       "        [ 23, 113,  30, 119],\n",
       "        [338, 113, 340, 114],\n",
       "        [228, 121, 251, 130],\n",
       "        [270, 121, 273, 124],\n",
       "        [485, 120, 497, 125],\n",
       "        [257, 125, 260, 130],\n",
       "        [485, 129, 491, 130],\n",
       "        [ 32, 137,  33, 146],\n",
       "        [239, 147, 243, 150],\n",
       "        [469, 178, 470, 179],\n",
       "        [453, 194, 454, 206],\n",
       "        [469, 203, 470, 205],\n",
       "        [355, 217, 359, 230],\n",
       "        [407, 232, 456, 300],\n",
       "        [375, 240, 423, 266],\n",
       "        [476, 242, 487, 251],\n",
       "        [107, 244, 117, 247],\n",
       "        [372, 244, 373, 260],\n",
       "        [407, 276, 408, 280],\n",
       "        [437, 299, 440, 300],\n",
       "        [437, 301, 441, 312],\n",
       "        [368, 302, 373, 304],\n",
       "        [448, 310, 454, 312],\n",
       "        [448, 321, 454, 358],\n",
       "        [420, 323, 445, 324],\n",
       "        [442, 344, 445, 358],\n",
       "        [161, 348, 164, 357],\n",
       "        [138, 390, 139, 397],\n",
       "        [447, 404, 454, 411],\n",
       "        [151, 420, 152, 421],\n",
       "        [154, 420, 156, 421],\n",
       "        [469, 420, 474, 425],\n",
       "        [140, 424, 141, 430],\n",
       "        [ 45, 434,  69, 470],\n",
       "        [ 79, 434,  98, 462],\n",
       "        [154, 435, 185, 499],\n",
       "        [190, 437, 205, 478],\n",
       "        [209, 443, 224, 462],\n",
       "        [111, 452, 121, 454],\n",
       "        [145, 456, 146, 462],\n",
       "        [151, 456, 152, 462],\n",
       "        [ 68, 469,  69, 470],\n",
       "        [ 84, 469,  95, 478],\n",
       "        [116, 477, 121, 478],\n",
       "        [209, 477, 214, 478],\n",
       "        [257, 479, 260, 481],\n",
       "        [387, 479, 390, 481],\n",
       "        [ 80, 481,  95, 487],\n",
       "        [113, 481, 130, 492],\n",
       "        [304, 480, 309, 481],\n",
       "        [259, 485, 260, 486],\n",
       "        [259, 491, 260, 493]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[0][:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 5), dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annot'][1][:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(0,5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 5))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_val = DataLoader(dataset_val, batch_size=16, shuffle=False, \n",
    "                                num_workers=4, collate_fn=bbox_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[183.1463, 202.3716, 412.8380, 377.4229]]), tensor([[  1.0119,   6.0711, 220.5850, 235.7628]]), tensor([[  1.0119,   6.0711, 162.9091, 190.2293]]), tensor([[  1.0119,   1.0119, 173.0277, 222.6087]]), tensor([[  1.0119,   1.0119, 240.8221, 266.1186]]), tensor([[ 63.7470, 190.2293, 267.1304, 356.1739]]), tensor([[112.3162, 235.7628, 306.5929, 410.8142]]), tensor([[100.1739, 254.9882, 302.5455, 414.8617]]), tensor([[ 94.1028, 229.6917, 340.9961, 419.9210]]), tensor([[217.5494, 238.7984, 390.5771, 409.8024]]), tensor([[291.4150, 278.2609, 437.1226, 422.9565]]), tensor([[299.5099, 318.7352, 455.3360, 456.3478]]), tensor([[207.4308, 242.8459, 302.5455, 343.0198]]), tensor([[233.7391, 251.9526, 333.9131, 339.9842]]), tensor([[344.0316, 168.9802, 509.9763, 402.7194]]), tensor([[322.7826, 134.5771, 512.0000, 436.1107]])]\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader_val:\n",
    "    #data['bboxes'][0]=torch.empty(0,5)\n",
    "    print(data['bboxes'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [copy.copy(dataset_val[i]) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'update',\n",
       " 'values']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(0,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 8))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 8), dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
