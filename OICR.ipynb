{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import bbox_collate\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset\n",
    "from utils import data2target\n",
    "from torchvision.ops import roi_align\n",
    "import copy\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imgaug import BoundingBoxesOnImage\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open('./config.yaml'))\n",
    "dataset_means = json.load(open(config['dataset']['mean_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROIPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(7)\n",
    "        \n",
    "    def forward(self, inputs, rois):\n",
    "        #rois: [torch(2000,4) x bs] \n",
    "        #output: bs, 2000, ch, h, w\n",
    "        n = min(list(map(lambda x: x.shape[0], rois)))\n",
    "        for i, tensor in enumerate(rois):\n",
    "            rois[i] = rois[i][:n,:]\n",
    "            rois[i].cuda()\n",
    "        rois = torch.stack(rois, dim=0) #tensor (bs, n, 4)\n",
    "        bs = rois.shape[0]\n",
    "        x1 = rois[:,:,0]\n",
    "        x2 = rois[:,:,2]\n",
    "        y1 = rois[:,:,1]\n",
    "        y2 = rois[:,:,3]\n",
    "        h, w = inputs.shape[2], inputs.shape[3]\n",
    "        x1 = np.floor(x1/512*w).type(torch.uint8)\n",
    "        x2 = np.ceil(x2/512*w).type(torch.uint8)\n",
    "        y1 = np.floor(y1/512*h).type(torch.uint8)\n",
    "        y2 = np.ceil(y2/512*h).type(torch.uint8)\n",
    "        \n",
    "        res = []\n",
    "        for batch in range(bs):\n",
    "            for i in range(n):\n",
    "                inp = inputs[batch, :, y1[batch,i]:y2[batch,i], x1[batch,i]:x2[batch,i]].unsqueeze(0) # 1, ch, h',w'\n",
    "                inp = self.max_pool(inp)\n",
    "                res.append(inp)\n",
    "        res = torch.cat(res, dim=0) #batch*dim, ch, 7, 7\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ROIPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, inputs, rois):\n",
    "        #rois: [torch(2000,4) x bs] \n",
    "        #output: bs, 2000, ch, h, w\n",
    "        n = min(list(map(lambda x: x.shape[0], rois)))\n",
    "        r = []\n",
    "        for i, tensor in enumerate(rois):\n",
    "            rois[i] = rois[i][:n,:]\n",
    "            tmp = torch.zeros(n, 1)\n",
    "            tmp[:] = i\n",
    "            tmp = torch.cat([tmp, rois[i]], dim=1)\n",
    "            r.append(tmp)\n",
    "        r = torch.cat(r, dim=0)\n",
    "        print(r.shape)\n",
    "        r.cuda()\n",
    "            \n",
    "            \n",
    "        h, w = inputs.shape[2], inputs.shape[3]\n",
    "        res = roi_align(inputs, r, 7, spatial_scale=w/512)\n",
    "        \n",
    "        print(res.shape) #batch*dim, ch, 7, 7\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vector_extractor(nn.Module):\n",
    "    \"\"\"input: images, proposals\n",
    "         output: feature vector\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_map = nn.Sequential(*list(models.resnet50(pretrained=True).children())[:-2])\n",
    "        self.roi_pool = ROIPool()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feature_vector = nn.Sequential(nn.Linear(2048, 1000),\n",
    "                                                                       nn.ReLU(inplace=True),\n",
    "                                                                       nn.Linear(1000, 500),\n",
    "                                                                       nn.ReLU(inplace=True))\n",
    "    def forward(self, inputs, rois):\n",
    "        f = self.feature_map(inputs)\n",
    "        f = self.roi_pool(f, rois)\n",
    "        f = self.gap(f).view(f.shape[0], f.shape[1]) #batch*proposal, ch\n",
    "        f = self.feature_vector(f) \n",
    "        return f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDN(nn.Module):\n",
    "    \"\"\"input: feature vector, labels\n",
    "         output: scores per proposal, loss\"\"\"\n",
    "    def __init__(self, bs):\n",
    "        super().__init__()\n",
    "        c_in = 500\n",
    "        self.bs = bs\n",
    "        self.layer_c = nn.Linear(c_in, 3)\n",
    "        self.layer_d = nn.Linear(c_in, 3)\n",
    "        self.softmax_c = nn.Softmax(dim=2)\n",
    "        self.softmax_d = nn.Softmax(dim=1)\n",
    "        self.loss = nn.BCELoss()\n",
    "        \n",
    "    def forward(self, inputs, labels):\n",
    "        bs, proposal = self.bs, inputs.shape[0]//self.bs\n",
    "        x_c = self.layer_c(inputs).view(bs, proposal, -1) #bs, proposal, 3\n",
    "        x_d = self.layer_d(inputs).view(bs, proposal, -1)\n",
    "        sigma_c = self.softmax_c(x_c)\n",
    "        sigma_d = self.softmax_d(x_d)\n",
    "        x_r = sigma_c * sigma_d #bs, proposal, 3\n",
    "        phi_c = x_r.sum(dim=1) #bs, 3\n",
    "        loss = self.loss(phi_c, labels)\n",
    "        \n",
    "        return x_r, loss\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICR(nn.Module):\n",
    "    \"\"\"input: feature vector (bs*proposal, ch)\n",
    "                     k-1th proposal scores(bs, proposal,3or4)\n",
    "                     supervision (label) (bs)\n",
    "                     ROI proposals\n",
    "         output: refined proposal scores, loss\"\"\"\n",
    "    def __init__(self, bs):\n",
    "        super().__init__()\n",
    "        c_in = 500\n",
    "        self.I_t = 0.5\n",
    "        self.bs = bs\n",
    "        self.fc = nn.Linear(c_in, 4)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        \"\"\"self.y_k = torch.zeros(bs, proposal, 4).cuda()\n",
    "        self.y_k[:, :, 3] = 1\n",
    "        self.w = torch.zeros(bs, proposal).cuda()\"\"\"\n",
    "        \n",
    "    def forward(self, inputs, pre_score, labels, rois):\n",
    "        bs, proposal = self.bs, inputs.shape[0]//self.bs\n",
    "        xr_k = self.fc(inputs).view(bs, proposal, -1) #bs, proposal, 4\n",
    "        xr_k = self.softmax(xr_k)\n",
    "        if pre_score == None:\n",
    "            return xr_k\n",
    "        _xr_k = xr_k.view(bs*proposal, -1)\n",
    "        self.y_k = torch.zeros(bs, proposal, 4).cuda()\n",
    "        self.y_k[:, :, 3] = 1\n",
    "        self.w = torch.zeros(bs, proposal).cuda()\n",
    "        I = torch.zeros(bs, proposal)\n",
    "        for batch in range(bs):\n",
    "            for c in range(3):\n",
    "                if labels[batch][c]:\n",
    "                    m = torch.max(pre_score[batch, :, c], 0)\n",
    "                    x = m[0].item()\n",
    "                    j = m[1].item()\n",
    "                    for r in range(proposal):\n",
    "                        _I = calc_iou(rois[batch][r], rois[batch][j])\n",
    "                        if _I > I[batch, r]:\n",
    "                            I[batch, r] = _I\n",
    "                            self.w[batch, r] = x\n",
    "                            if _I > self.I_t:\n",
    "                                self.y_k[batch, r, c] = 1\n",
    "                                self.y_k[batch, r, 3] = 0\n",
    "        self.y_k = self.y_k.view(bs*proposal, -1)\n",
    "        self.w = self.w.view(bs*proposal, 1)\n",
    "        loss = self.loss(_xr_k.cuda().float(), torch.max(self.y_k, 1)[1])\n",
    "        loss = torch.sum(self.w*loss)\n",
    "        return xr_k, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(a, b):\n",
    "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "\n",
    "    iw = torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]) - torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0])\n",
    "    ih = torch.min(torch.unsqueeze(a[:, 3], dim=1), b[:, 3]) - torch.max(torch.unsqueeze(a[:, 1], 1), b[:, 1])\n",
    "\n",
    "    iw = torch.clamp(iw, min=0)\n",
    "    ih = torch.clamp(ih, min=0)\n",
    "\n",
    "    ua = torch.unsqueeze((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), dim=1) + area - iw * ih\n",
    "\n",
    "    ua = torch.clamp(ua, min=1e-8)\n",
    "\n",
    "    intersection = iw * ih\n",
    "\n",
    "    IoU = intersection / ua\n",
    "\n",
    "    return IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO pseudo label を読み込むようにdataset と　dataloaderを改良\n",
    "#TODO 各モジュールが正常に動くか逐次チェック\n",
    "#TODO main()を作成してtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalBboxDataset(Dataset):\n",
    "    def __init__(self, annotation, data_path, pseudo_path=None, transform=None):\n",
    "        if isinstance(annotation, dict):\n",
    "            self.coco = COCO()\n",
    "            self.coco.dataset = annotation\n",
    "            self.coco.createIndex()\n",
    "        else:\n",
    "            self.coco = COCO(annotation)\n",
    "        self.data_path = data_path\n",
    "        self.imgids = self.coco.getImgIds()\n",
    "        self.set_transform(transform)\n",
    "        self.load_classes()\n",
    "        self.p_path = pseudo_path\n",
    "        if pseudo_path != None:\n",
    "            with open(pseudo_path, \"r\") as json_open:\n",
    "                self.p_file = json.load(json_open)\n",
    "            \n",
    "\n",
    "    def load_classes(self):\n",
    "        # load class names (name -> label)\n",
    "        categories = self.coco.loadCats(self.coco.getCatIds())\n",
    "        categories.sort(key=lambda x: x['id'])\n",
    "\n",
    "        self.classes             = {}\n",
    "        self.coco_labels         = {}\n",
    "        self.coco_labels_inverse = {}\n",
    "        for c in categories:\n",
    "            self.coco_labels[len(self.classes)] = c['id']\n",
    "            self.coco_labels_inverse[c['id']] = len(self.classes)\n",
    "            self.classes[c['name']] = len(self.classes)\n",
    "\n",
    "        # also load the reverse (label -> name)\n",
    "        self.labels = {}\n",
    "        for key, value in self.classes.items():\n",
    "            self.labels[value] = key\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return: Number of images\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.imgids)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        if isinstance(i, slice):\n",
    "            imgids = self.imgids[i]\n",
    "            return self.split_by_imgids(imgids)\n",
    "        else:\n",
    "            return self.transform({\n",
    "                'img': self.load_image(i),\n",
    "                **self.load_annotations(i)\n",
    "            })\n",
    "    \n",
    "    def load_image(self, i):\n",
    "        '''\n",
    "        Args:\n",
    "            i (int): Index of image\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Selected image\n",
    "        '''\n",
    "        imgid = self.imgids[i]\n",
    "        img_info = self.coco.loadImgs(imgid)[0]\n",
    "        img_path = os.path.join(self.data_path, img_info['file_name'])\n",
    "        img = Image.open(img_path)\n",
    "        return np.array(img)\n",
    "    \n",
    "    def load_annotations(self, i):\n",
    "        '''\n",
    "        Args:\n",
    "            i (int): Index of image\n",
    "        \n",
    "        Returns:\n",
    "            dict: Annotation of the selected image\n",
    "        '''\n",
    "        imgid = self.imgids[i]\n",
    "        annids = self.coco.getAnnIds(imgIds=imgid)\n",
    "        anno_info = self.coco.loadAnns(annids)\n",
    "        annotations     = np.zeros((0, 5))\n",
    "        bboxes, labels = [], []\n",
    "        \n",
    "        for anno in anno_info:\n",
    "            bboxes.append(anno['bbox'])\n",
    "            label = self.coco.getCatIds().index(anno['category_id'])\n",
    "            labels.append(label)\n",
    "\n",
    "            if anno['bbox'][2] < 1 or anno['bbox'][3] < 1:\n",
    "                continue\n",
    "\n",
    "            annotation        = np.zeros((1, 5))\n",
    "            annotation[0, :4] = anno['bbox']\n",
    "            annotation[0, 4]  = self.coco_label_to_label(anno['category_id'])\n",
    "            annotations       = np.append(annotations, annotation, axis=0)\n",
    "\n",
    "        # transform from [x, y, w, h] to [x1, y1, x2, y2]\n",
    "        annotations[:, 2] = annotations[:, 0] + annotations[:, 2]\n",
    "        annotations[:, 3] = annotations[:, 1] + annotations[:, 3]\n",
    "        \n",
    "        bboxes = np.array(bboxes, dtype=np.float32).reshape(-1, 4)\n",
    "        bboxes[:, 2:] += bboxes[:, :2]  # xywh -> xyxy\n",
    "        labels = np.array(labels, dtype=np.int)\n",
    "        p_bboxes = []\n",
    "        if self.p_path != None:\n",
    "            p_bboxes = self.p_file[\"pseudo_annotations\"][0][\"p_bbox2\"] #[f\"p_bbox{imgid}\"]\n",
    "        \n",
    "        return {\n",
    "            'annot' : annotations,\n",
    "            'bboxes': bboxes,\n",
    "            'labels': labels,\n",
    "            'p_bboxes':p_bboxes\n",
    "        }\n",
    "    \n",
    "    def set_transform(self, transform):\n",
    "        '''\n",
    "        Args:\n",
    "            transform (function): Function to transform\n",
    "        '''\n",
    "        self.transform = transform if transform else lambda x: x\n",
    "    \n",
    "    def split(self, split, split_path):\n",
    "        if not isinstance(split, (tuple, list, set)):\n",
    "            split = split,\n",
    "        split_data = json.load(open(split_path))\n",
    "\n",
    "        imgids = []\n",
    "        for s in split:\n",
    "            imgids += split_data['image_id'][s]\n",
    "        \n",
    "        return self.split_by_imgids(imgids)\n",
    "        \n",
    "    def split_by_imgids(self, imgids):\n",
    "        coco_format = {\n",
    "            'info': self.coco.dataset['info'],\n",
    "            'categories': self.coco.dataset['categories'],\n",
    "            'images': self.coco.loadImgs(imgids),\n",
    "            'annotations': self.coco.loadAnns(self.coco.getAnnIds(imgIds=imgids))\n",
    "        }\n",
    "        return MedicalBboxDataset(coco_format, self.data_path, self.p_path, self.transform)\n",
    "\n",
    "    def integrate_classes(self, new_cats, idmap):\n",
    "        annotations = copy.deepcopy(self.coco.dataset['annotations'])\n",
    "        for anno in annotations:\n",
    "            anno['category_id'] = idmap[anno['category_id']]\n",
    "\n",
    "        coco_format = {\n",
    "            'info': self.coco.dataset['info'],\n",
    "            'categories': new_cats,\n",
    "            'images': self.coco.dataset['images'],\n",
    "            'annotations': annotations\n",
    "        }\n",
    "        return MedicalBboxDataset(coco_format, self.data_path, self.p_path, self.transform)\n",
    "\n",
    "    def with_annotation_imgids(self):\n",
    "        imgids = []\n",
    "        for catid in self.coco.getCatIds():\n",
    "            imgids += self.coco.getImgIds(catIds=catid)\n",
    "        return imgids\n",
    "    \n",
    "    def with_annotation(self):\n",
    "        imgids = self.with_annotation_imgids()\n",
    "        return self.split_by_imgids(imgids)\n",
    "    \n",
    "    def without_annotation(self):\n",
    "        imgids = list(set(self.imgids) - set(self.with_annotation_imgids()))\n",
    "        return self.split_by_imgids(imgids)\n",
    "    \n",
    "    def get_coco(self):\n",
    "        return self.coco\n",
    "\n",
    "    def get_category_names(self):\n",
    "        catids = self.coco.getCatIds()\n",
    "        categories = self.coco.loadCats(catids)\n",
    "        return [cat['name'] for cat in categories]\n",
    "    def coco_label_to_label(self, coco_label):\n",
    "        return self.coco_labels_inverse[coco_label]\n",
    "\n",
    "\n",
    "    def label_to_coco_label(self, label):\n",
    "        return self.coco_labels[label]\n",
    "\n",
    "    def image_aspect_ratio(self, image_index):\n",
    "        image = self.coco.loadImgs(self.imgids[image_index])[0]\n",
    "        return float(image['width']) / float(image['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToFixedSize:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        data = copy.copy(data)\n",
    "        \n",
    "        raw_h, raw_w = data['img'].shape[:2]\n",
    "        mag = min(self.size[0]/raw_h, self.size[1]/raw_w)\n",
    "        h = round(raw_h * mag)\n",
    "        w = round(raw_w * mag)\n",
    "        \n",
    "        image = data['img']\n",
    "        data['img'] = np.zeros([*self.size, data['img'].shape[2]])\n",
    "        data['img'][:h, :w] = cv2.resize(image, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        if data[\"p_bboxes\"].size > 0:\n",
    "            data['p_bboxes'][:, 0::2] *= w / raw_w\n",
    "            data['p_bboxes'][:, 1::2] *= h / raw_h\n",
    "            data['p_bboxes'][:, 0:2] = np.floor(data['p_bboxes'][:, 0:2])\n",
    "            data['p_bboxes'][:, 2:4] = np.ceil(data['p_bboxes'][:, 2:4])\n",
    "        else:\n",
    "            data['bboxes'][:, 0::2] *= w / raw_w\n",
    "            data['bboxes'][:, 1::2] *= h / raw_h\n",
    "        \n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "class Augmentation:\n",
    "    def __init__(self, settings):\n",
    "        seq = []\n",
    "        \n",
    "        def active(t):\n",
    "            return t in settings and settings[t] != False\n",
    "        \n",
    "        # 回転, 左右反転, 上下反転で8パターン\n",
    "        if active('flip'):\n",
    "            seq += [\n",
    "                iaa.Affine(rotate=iap.Binomial(0.5)*90),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5)\n",
    "            ]\n",
    "        if active('rotate_flip_shear'):\n",
    "            seq += [\n",
    "                iaa.Affine(rotate=iap.DiscreteUniform(-179,180),shear=(-10, 10)),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5)\n",
    "            ]\n",
    "        \n",
    "        if active('gamma_per_channel'):\n",
    "            low, high = settings['gamma_per_channel']\n",
    "            seq.append(iaa.GammaContrast([low, high], per_channel=True))\n",
    "            \n",
    "        if active('gamma'):\n",
    "            low, high = settings['gamma']\n",
    "            seq.append(iaa.GammaContrast([low, high]))\n",
    "        \n",
    "        if active('gaussnoise'):\n",
    "            intensity = settings['gaussnoise']\n",
    "            seq.append(\n",
    "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, intensity), per_channel=1)\n",
    "            )\n",
    "        \n",
    "        self.seq = iaa.Sequential(seq)\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        data = copy.copy(data)\n",
    "        seq = self.seq.to_deterministic()\n",
    "        image = data['img']\n",
    "        data[\"p_bboxes\"] = np.array(data[\"p_bboxes\"])\n",
    "        if data[\"p_bboxes\"].size > 0:\n",
    "            bboxes = BoundingBoxesOnImage.from_xyxy_array(data['p_bboxes'], shape=image.shape)\n",
    "            image, bboxes = seq(image=image, bounding_boxes=bboxes)\n",
    "            bboxes = bboxes.clip_out_of_image()\n",
    "            data['p_bboxes'] = BoundingBoxesOnImage.to_xyxy_array(bboxes)\n",
    "        else:\n",
    "            bboxes = BoundingBoxesOnImage.from_xyxy_array(data['bboxes'], shape=image.shape)\n",
    "            image, bboxes = seq(image=image, bounding_boxes=bboxes)\n",
    "            bboxes = bboxes.clip_out_of_image()\n",
    "            data['bboxes'] = BoundingBoxesOnImage.to_xyxy_array(bboxes)\n",
    "        data['img'] = image\n",
    "        \n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class Normalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        data = copy.copy(data)\n",
    "        data['img'] = (data['img'] - self.mean) / self.std\n",
    "        return data\n",
    "\n",
    "class UnNormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        data = copy.copy(data)\n",
    "        data['img'] = data['img'].squeeze().permute(1,2,0).numpy()\n",
    "        data['img'] = (data['img'] * self.std) + self.mean\n",
    "        data['img'] = data['img'].astype(np.uint8)\n",
    "        #data['img'] = data['img'].transpose(2,0,1)\n",
    "        return data\n",
    "\n",
    "\n",
    "class HWCToCHW:\n",
    "    def __call__(self, data):\n",
    "        data = copy.copy(data)\n",
    "        data['img'] = data['img'].transpose(2, 0, 1)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfiniteSampler:\n",
    "    '''\n",
    "    与えられたLength内に収まる数値を返すIterator\n",
    "    '''\n",
    "    def __init__(self, length, random=True, generator=None):\n",
    "        self.length = length\n",
    "        self.random = random\n",
    "        if random:\n",
    "            self.generator = torch.Generator() if generator is None else generator\n",
    "        self.stock = []\n",
    "        \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            yield self.get(1)[0]\n",
    "    \n",
    "    def get(self, n):\n",
    "        while len(self.stock) < n:\n",
    "            self.extend_stock()\n",
    "        \n",
    "        indices = self.stock[:n]\n",
    "        self.stock = self.stock[n:]\n",
    "        \n",
    "        return indices\n",
    "        \n",
    "    def extend_stock(self):\n",
    "        if self.random:\n",
    "            self.stock += torch.randperm(self.length, generator=self.generator).numpy().tolist()\n",
    "        else:\n",
    "            self.stock += list(range(self.length))\n",
    "\n",
    "\n",
    "class MixedRandomSampler(torch.utils.data.sampler.Sampler):\n",
    "    '''\n",
    "    複数のデータセットを一定の比で混ぜながら、指定した長さだけIterationするSampler\n",
    "    '''\n",
    "    def __init__(self, datasets, length, ratio=None, generator=None):\n",
    "        self.catdataset = torch.utils.data.ConcatDataset(datasets)\n",
    "        self.length = length\n",
    "        \n",
    "        self.generator = torch.Generator() if generator is None else generator\n",
    "        \n",
    "        self.dataset_lengths = [len(dataset) for dataset in datasets]\n",
    "        if ratio is None:\n",
    "            self.ratio = torch.tensor(self.dataset_lengths, dtype=torch.float)\n",
    "        else:\n",
    "            self.ratio = torch.tensor(ratio, dtype=torch.float)\n",
    "            \n",
    "        self.samplers = [InfiniteSampler(l, generator=self.generator) for l in self.dataset_lengths]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        start_with = torch.cumsum(torch.tensor([0] + self.dataset_lengths), dim=0)\n",
    "        selected = self.random_choice(self.ratio, self.length)\n",
    "        \n",
    "        indices = torch.empty(self.length, dtype=torch.int)\n",
    "        \n",
    "        for i in range(len(self.ratio)):\n",
    "            mask = selected == i\n",
    "            n_selected = mask.sum().item()\n",
    "            indices[mask] = torch.tensor(self.samplers[i].get(n_selected), dtype=torch.int) + start_with[i]\n",
    "        \n",
    "        indices = indices.numpy().tolist()[0::1]\n",
    "        \n",
    "        return iter(indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(self.length)\n",
    "    \n",
    "    def get_concatenated_dataset(self):\n",
    "        return self.catdataset\n",
    "    \n",
    "    def random_choice(self, p, size):\n",
    "        random = torch.rand(size, generator=self.generator)\n",
    "        bins = torch.cumsum(p / p.sum(), dim=0)\n",
    "        choice = torch.zeros(size, dtype=torch.int)\n",
    "\n",
    "        for i in range(len(p) - 1):\n",
    "            choice[random > bins[i]] = i + 1\n",
    "\n",
    "        return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_path = \"/data/unagi0/masaoka/endoscopy/annotations/pseudo_annotations.json\"\n",
    "config[\"batchsize\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "        Augmentation(config['augmentation']),\n",
    "        ToFixedSize([config['inputsize']] * 2),  # inputsize x inputsizeの画像に変換\n",
    "        Normalize(dataset_means['mean'], dataset_means['std']),\n",
    "        HWCToCHW()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.48s)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_all = MedicalBboxDataset(\n",
    "    config['dataset']['annotation_file'],\n",
    "    config['dataset']['image_root'],\n",
    "    pseudo_path=p_path)\n",
    "if 'class_integration' in config['dataset']:\n",
    "    dataset_all = dataset_all.integrate_classes(\n",
    "        config['dataset']['class_integration']['new'],\n",
    "        config['dataset']['class_integration']['map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_all = dataset_all.split(config['dataset']['train'], config['dataset']['split_file'])\n",
    "train_all.set_transform(transform)\n",
    "train_normal = train_all.without_annotation()\n",
    "train_anomaly = train_all.with_annotation()\n",
    "n_fg_class = len(dataset_all.get_category_names()) \n",
    "\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(0)\n",
    "sampler = MixedRandomSampler(\n",
    "    [train_normal, train_anomaly],\n",
    "    config[\"n_iteration\"]*config[\"batchsize\"] ,\n",
    "    ratio=[config['negative_ratio'], 1],\n",
    "    generator=generator)\n",
    "batch_sampler = torch.utils.data.sampler.BatchSampler(sampler, config[\"batchsize\"] , drop_last=False)\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    sampler.get_concatenated_dataset(),\n",
    "    num_workers=8,\n",
    "    batch_sampler=batch_sampler,\n",
    "    collate_fn=bbox_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  0.,   0., 512., 512.],\n",
      "        [318., 474., 363., 512.],\n",
      "        [126.,   1., 512., 491.],\n",
      "        ...,\n",
      "        [189., 168., 209., 185.],\n",
      "        [203.,   0., 226.,  10.],\n",
      "        [334., 294., 372., 335.]]), tensor([[  0.,   0., 512., 512.],\n",
      "        [351.,   0., 392.,  51.],\n",
      "        [138.,  45., 512., 512.],\n",
      "        ...,\n",
      "        [180., 320., 200., 336.],\n",
      "        [171., 496., 193., 512.],\n",
      "        [342., 191., 377., 230.]])]\n"
     ]
    }
   ],
   "source": [
    "for i in dataloader_train:\n",
    "    print(i[\"p_bboxes\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1988, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[\"p_bboxes\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1970, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[\"p_bboxes\"][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "v = vector_extractor()\n",
    "v.cuda()\n",
    "print(\"clear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = v(i[\"img\"].cuda().float(),i[\"p_bboxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, n, t, v, u= data2target(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "m = MIDN(config[\"batchsize\"])\n",
    "m.cuda()\n",
    "print(\"clear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = m(f,labels.cuda().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "icr1 = ICR(config[\"batchsize\"])\n",
    "icr1.cuda()\n",
    "print(\"clear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = icr1(f, g[0], labels.cuda(), i[\"p_bboxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "icr2 = ICR(config[\"batchsize\"])\n",
    "icr2.cuda()\n",
    "print(\"clear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = icr2(f, h[0], labels.cuda(), i[\"p_bboxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OICR(nn.Module):\n",
    "    def __init__(self,bs):\n",
    "        super().__init__()\n",
    "        self.v_extractor = vector_extractor()\n",
    "        self.midn = MIDN(bs)\n",
    "        self.icr1 = ICR(bs)\n",
    "        self.icr2 = ICR(bs)\n",
    "        self.icr3 = ICR(bs)\n",
    "    \n",
    "    def forward(self, inputs, labels, rois):\n",
    "        if self.training:\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            x, midn_loss = self.midn(v, labels)\n",
    "            x, loss1 = self.icr1(v, x, labels, rois)\n",
    "            x, loss2 = self.icr2(v, x, labels, rois)\n",
    "            x, loss3 = self.icr3(v, x, labels, rois) \n",
    "            loss = midn_loss + loss1 + loss2 + loss3\n",
    "            return x, loss  \n",
    "        else:\n",
    "            v = self.v_extractor(inputs, rois)\n",
    "            x = self.icr3(v, None, labels, rois) \n",
    "            x, rois = x[0], rois[0].cuda()\n",
    "            s, i = torch.max(x, 1)\n",
    "            sort = torch.argsort(s, descending=True)\n",
    "            s, i = s.view(-1,1), i.view(-1,1).cuda().float()\n",
    "            print(s.is_cuda, i.is_cuda, rois.is_cuda)\n",
    "            cat = torch.cat([s, i ,rois], dim=1)\n",
    "            cat = cat[sort, :]\n",
    "            scores = cat[:, 0]\n",
    "            labels = cat[:, 1]\n",
    "            bboxes = cat[:, 2:]\n",
    "            \n",
    "            return scores, labels, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "oicr = OICR(config[\"batchsize\"])\n",
    "oicr.cuda()\n",
    "labels, n, t, v, u= data2target(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = oicr(i[\"img\"].cuda().float(),labels.cuda().float(), i[\"p_bboxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "oicr.eval()\n",
    "print(\"clear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "score, label, box = oicr(i[\"img\"].cuda().float(),labels.cuda().float(), i[\"p_bboxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1964, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
